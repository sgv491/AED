{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production Technology\n",
    "\n",
    "The dataset contains `N = 441` firms observed over `T = 12` years, 1968-1979. There variables are: \n",
    "* `lcap`: Log of capital stock, $k_{it}$ \n",
    "* `lemp`: log of employment, $\\ell_{it}$ \n",
    "* `ldsa`: log of deflated sales, $y_{it}$\n",
    "* `year`: the calendar year of the observation, `year` $ = 1968, ..., 1979$, \n",
    "* `firmid`: anonymized indicator variable for the firm, $i = 1, ..., N$, with $N=441$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2\n",
    "import numpy.linalg as la\n",
    "from numpy import linalg as la\n",
    "import scipy.stats as st\n",
    "import importlib.util, sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- loader ---\n",
    "def load_firm_data(path=\"firms.csv\"):\n",
    "    dat = pd.read_csv(path)\n",
    "    y = dat[\"ldsa\"].values.reshape(-1, 1)\n",
    "    x = np.column_stack([np.ones(dat.shape[0]), dat[\"lcap\"].values, dat[\"lemp\"].values])\n",
    "    T = dat[\"year\"].nunique()  # 12\n",
    "    label_y = \"Log deflated sales\"\n",
    "    label_x = [\"Constant\", \"Capital\", \"Labor\"]\n",
    "    return y, x, T, dat[\"year\"].values, label_y, label_x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled OLS\n",
      "Dependent variable: Log deflated sales\n",
      "\n",
      "            Beta      Se    t-values\n",
      "--------  ------  ------  ----------\n",
      "Constant  0.0000  0.0050      0.0000\n",
      "Capital   0.3100  0.0091     33.9237\n",
      "Labor     0.6748  0.0102     66.4625\n",
      "R² = 0.914\n",
      "σ² = 0.131\n"
     ]
    }
   ],
   "source": [
    "import w3_LinearModels as lm\n",
    "\n",
    "# Load firm data\n",
    "y, x, T, year, label_y, label_x = load_firm_data()\n",
    "\n",
    "# Pooled OLS estimation\n",
    "pols_result = lm.estimate(y, x, T=T)\n",
    "\n",
    "# Print results in a nice table\n",
    "lm.print_table((label_y, label_x), pols_result, title=\"Pooled OLS\", floatfmt='.4f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled OLS (Robust SE)\n",
      "Dependent variable: Log deflated sales\n",
      "\n",
      "            Beta      Se    t-values\n",
      "--------  ------  ------  ----------\n",
      "Constant  0.0000  0.0161      0.0000\n",
      "Capital   0.3100  0.0324      9.5810\n",
      "Labor     0.6748  0.0366     18.4526\n",
      "R² = 0.914\n",
      "σ² = 0.131\n"
     ]
    }
   ],
   "source": [
    "pols_result_robust = lm.estimate(y, x, T=T, robust_se=True)\n",
    "lm.print_table((label_y, label_x), pols_result_robust, title=\"Pooled OLS (Robust SE)\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zero_columns(x, label_x, tol=1e-10):\n",
    "    \"\"\"\n",
    "    Remove columns that are effectively zero and return filtered matrix and labels.\n",
    "\n",
    "    Args:\n",
    "        x: numpy array with regressors.\n",
    "        label_x: list of labels for each column in x.\n",
    "        tol: numerical tolerance for treating a column as zero (default 1e-10).\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (x_nonzero, label_nonzero).\n",
    "    \"\"\"\n",
    "    mask = ~np.all(np.isclose(x, 0.0, atol=tol), axis=0)\n",
    "    x_nonzero = x[:, mask]\n",
    "    label_nonzero = [label_x[i] for i, keep in enumerate(mask) if keep]\n",
    "    return x_nonzero, label_nonzero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CRS restriction helpers ---\n",
    "def _crs_wald(results, start_idx):\n",
    "    \"\"\"Generic Wald test for the CRS restriction beta_K + beta_L = 1.\"\"\"\n",
    "    b = results['b_hat'][start_idx:, :]\n",
    "    cov = results['cov'][start_idx:, start_idx:]\n",
    "    R = np.array([[1.0, 1.0]])\n",
    "    q = np.array([[1.0]])\n",
    "    diff = R @ b - q\n",
    "    var_Rb = R @ cov @ R.T\n",
    "    W = (diff.T @ la.inv(var_Rb) @ diff).item()\n",
    "    crit_val = chi2.ppf(0.95, 1)\n",
    "    p_value = 1 - st.chi2.cdf(W, 1)\n",
    "    return W, crit_val, p_value\n",
    "\n",
    "def crs_test(results):\n",
    "    \"\"\"CRS test for models that include a constant (skip the first coefficient).\"\"\"\n",
    "    return _crs_wald(results, 1)\n",
    "\n",
    "def crs_test_fd(results):\n",
    "    \"\"\"CRS test for first-difference models without a constant.\"\"\"\n",
    "    return _crs_wald(results, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Effects\n",
      "Dependent variable: Log deflated sales\n",
      "\n",
      "           Beta      Se    t-values\n",
      "-------  ------  ------  ----------\n",
      "Capital  0.1546  0.0299      5.1630\n",
      "Labor    0.6942  0.0417     16.6674\n",
      "R² = 0.477\n",
      "σ² = 0.018\n"
     ]
    }
   ],
   "source": [
    "# Transform the data\n",
    "Q_T = np.eye(T) - 1/T * np.ones((T, T))\n",
    "y_dot = lm.perm(Q_T, y)\n",
    "x_dot = lm.perm(Q_T, x)\n",
    "\n",
    "# Remove the columns that are only zeroes\n",
    "x_dot, label_x_dot = remove_zero_columns(x_dot, label_x)\n",
    "\n",
    "# Estimate \n",
    "fe_result = lm.estimate(y_dot, x_dot, transform='fe', T=T, robust_se=True)\n",
    "lm.print_table((label_y, label_x_dot), fe_result, title=\"Fixed Effects\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# CRS test for the fixed-effects output regression\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m W_fe, crit_fe, pval_fe \u001b[38;5;241m=\u001b[39m crs_test(fe_result)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRS Wald test (FE): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mW_fe\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCritical value (5%): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcrit_fe\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m, in \u001b[0;36mcrs_test\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcrs_test\u001b[39m(results):\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"CRS test for models that include a constant (skip the first coefficient).\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _crs_wald(results, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m, in \u001b[0;36m_crs_wald\u001b[0;34m(results, start_idx)\u001b[0m\n\u001b[1;32m      6\u001b[0m R \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m]])\n\u001b[1;32m      7\u001b[0m q \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1.0\u001b[39m]])\n\u001b[0;32m----> 8\u001b[0m diff \u001b[38;5;241m=\u001b[39m R \u001b[38;5;241m@\u001b[39m b \u001b[38;5;241m-\u001b[39m q\n\u001b[1;32m      9\u001b[0m var_Rb \u001b[38;5;241m=\u001b[39m R \u001b[38;5;241m@\u001b[39m cov \u001b[38;5;241m@\u001b[39m R\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     10\u001b[0m W \u001b[38;5;241m=\u001b[39m (diff\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m la\u001b[38;5;241m.\u001b[39minv(var_Rb) \u001b[38;5;241m@\u001b[39m diff)\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 2)"
     ]
    }
   ],
   "source": [
    "# CRS test for the fixed-effects output regression\n",
    "W_fe, crit_fe, pval_fe = crs_test(fe_result)\n",
    "print(f\"CRS Wald test (FE): {W_fe:.4f}\")\n",
    "print(f\"Critical value (5%): {crit_fe:.4f}\")\n",
    "print(f\"p-value: {pval_fe:.4f}\")\n",
    "fe_output_result = fe_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "D_T = - np.eye(T-1, T) + np.eye(T-1, T, k=1)\n",
    "y_diff = lm.perm(D_T, y)\n",
    "x_diff = lm.perm(D_T, x)\n",
    "\n",
    "# Remove the columns that are only zeroes\n",
    "x_diff, label_x_diff = remove_zero_columns(x_diff, label_x)\n",
    "\n",
    "# Estimate \n",
    "fd_result = lm.estimate(y_diff, x_diff, transform='fd', T=T-1, robust_se=True)\n",
    "lm.print_table((label_y, label_x_diff), fd_result, title=\"First Difference\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRS test for the first-difference output regression\n",
    "W_fd, crit_fd, pval_fd = crs_test_fd(fd_result)\n",
    "print(f\"CRS Wald test (FD): {W_fd:.4f}\")\n",
    "print(f\"Critical value (5%): {crit_fd:.4f}\")\n",
    "print(f\"p-value: {pval_fd:.4f}\")\n",
    "fd_output_result = fd_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "P_T = np.ones((1,T)) * 1/T\n",
    "y_mean = lm.perm(P_T, y)\n",
    "x_mean = lm.perm(P_T, x)\n",
    "\n",
    "# Estimate \n",
    "be_result = lm.estimate(y_mean, x_mean, transform='be', T=T)\n",
    "lm.print_table((label_y, label_x), be_result, title=\"Between Estimator\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate lambda (note lambda is a reserved keyword in Python, so we use _lambda instead)\n",
    "sigma2_u = fe_result['sigma2']\n",
    "sigma2_w = be_result['sigma2']\n",
    "sigma2_c = sigma2_w - 1/T * sigma2_u\n",
    "_lambda = 1 - np.sqrt(sigma2_u / (sigma2_u + T*sigma2_c))\n",
    "\n",
    "# Print lambda \n",
    "print(f'Lambda is approximately equal to {_lambda.item():.4f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "P_T_full = np.ones((T, T)) / T\n",
    "C_T = np.eye(T) - _lambda * P_T_full\n",
    "y_re = lm.perm(C_T, y)\n",
    "x_re = lm.perm(C_T, x)\n",
    "\n",
    "# Estimate \n",
    "re_result = lm.estimate(y_re, x_re, transform='re', T=T, robust_se=True)\n",
    "lm.print_table((label_y, label_x), re_result, title=\"Random Effects\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRS test for the random-effects output regression\n",
    "W_re, crit_re, pval_re = crs_test(re_result)\n",
    "print(f\"CRS Wald test (RE): {W_re:.4f}\")\n",
    "print(f\"Critical value (5%): {crit_re:.4f}\")\n",
    "print(f\"p-value: {pval_re:.4f}\")\n",
    "re_output_result = re_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Unpack HAUSMAN test\n",
    "b_fe = fe_result['b_hat'][1:3,:]      # Select only Capital and Labor coefficients\n",
    "b_re = re_result['b_hat'][1:3,:]      # Select only Capital and Labor coefficients\n",
    "cov_fe = fe_result['cov'][1:3,1:3]    # Select only Capital and Labor covariance\n",
    "cov_re = re_result['cov'][1:3,1:3]    # Select only Capital and Labor covariance\n",
    "\n",
    "# Calculate the test statistic\n",
    "b_diff = b_fe - b_re\n",
    "cov_diff = cov_fe - cov_re\n",
    "H = b_diff.T @ la.inv(cov_diff) @ b_diff\n",
    "\n",
    "# Find critical value and p-value at 5% significance level of chi^2 with M degrees of freedom\n",
    "M = len(b_diff)\n",
    "crit_val = chi2.ppf(0.95, M)\n",
    "p_val = 1 - chi2.cdf(H.item(), M)\n",
    "\n",
    "# Print the results\n",
    "print(f'The Hausman test statistic is {H.item():.2f}.')\n",
    "print(f'The critical value at a 5% significance level is {crit_val:.2f}.')\n",
    "print(f'The p-value is {p_val:.18f}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "denne sektion skal nok ind i py filen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from tabulate import tabulate\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Supress Future Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Import this weeks LinearModels .py file\n",
    "import w2_LinearModels_post as lm\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the data into numpy. \n",
    "data = pd.read_csv('firms.csv')\n",
    "id_array = np.array(data.iloc[:, 0])\n",
    "\n",
    "# Count how many persons we have. This returns a tuple with the unique IDs,\n",
    "# and the number of times each person is observed.\n",
    "unique_id = np.unique(id_array, return_counts=True)\n",
    "N = unique_id[0].size\n",
    "T = int(unique_id[1].mean())\n",
    "year = np.array(data.iloc[:, 1], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the rest of the data into arrays.\n",
    "# Load the rest of the data into arrays.\n",
    "y = data['lcap'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "# x needs to have a constant vector in the first row. How would you add this? \n",
    "# Note that the order is set to match the order of variables in the model.\n",
    "x = np.column_stack([\n",
    "    np.ones(N * T),\n",
    "    data['lemp'].to_numpy(),\n",
    "    data['ldsa'].to_numpy()\n",
    "])\n",
    "\n",
    "# Lets also make some variable names\n",
    "label_y = 'Log capital'\n",
    "label_x = [\n",
    "    'Constant',\n",
    "    'Log employment',\n",
    "    'Log DSA'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate coefficients\n",
    "b_hat = lm.est_ols(y,x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the residuals\n",
    "resid = y - x @ b_hat\n",
    "\n",
    "# Calculate estimate of variance of residuals\n",
    "SSR = resid.T @ resid\n",
    "K = x.shape[1]\n",
    "sigma = SSR / (N*T - K)\n",
    "\n",
    "# Calculate the variance-covariance matrix\n",
    "cov = sigma * la.inv(x.T @ x)\n",
    "\n",
    "# Calculate the standard errors \n",
    "# Make sure to output the result in a vector\n",
    "se = np.sqrt(np.diag(cov)).reshape(-1,1)\n",
    "\n",
    "#Print results\n",
    "for label, b_k, se_k in zip(label_x, b_hat, se):\n",
    "    print(f'{label:16}: {b_k[0]:7.4f}    ({se_k[0]:6.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate model using OLS\n",
    "ols_result = lm.estimate(y,x, N=N, T=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformation matrix\n",
    "def demeaning_matrix(T):\n",
    "    Q_T = np.eye(T) - np.tile(1/T, (T, T))\n",
    "    return Q_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "y_demean = lm.perm(Q_T, y)\n",
    "x_demean = lm.perm(Q_T, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to check rank of demeaned matrix, and return its eigenvalues.\n",
    "def check_rank(x):\n",
    "    print(f'Rank of demeaned x: {la.matrix_rank(x)}')\n",
    "    lambdas, V = la.eig(x.T@x)\n",
    "    np.set_printoptions(suppress=True)  # This is just to print nicely.\n",
    "    print(f'Eigenvalues of within-transformed x: {lambdas.round(decimals=0)}')\n",
    "    print(V)\n",
    "    # Use eigen vectors to identify which variables are dropped.\n",
    "\n",
    "# Check rank of demeaned x\n",
    "check_rank(x_demean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose variables to include in fixed effects model\n",
    "x_demean = x_demean[:, 1:5]\n",
    "label_x_fe = label_x[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate FE OLS using the demeaned variables.\n",
    "fe_result = lm.estimate(y_demean, x_demean, transform='fe', N=N, T=T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformation matrix\n",
    "def fd_matrix(T):\n",
    "    D_T = np.eye(T) - np.eye(T, k=-1)\n",
    "    D_T = D_T[1:]\n",
    "    return D_T\n",
    "\n",
    "# Print the matrix\n",
    "D_T = fd_matrix(T)\n",
    "print(f'First differening matrix for T={T} \\n', D_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data.\n",
    "y_diff = lm.perm(D_T, y)\n",
    "x_diff = lm.perm(D_T, x)\n",
    "\n",
    "# Print x_diff\n",
    "print(x_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check rank condition.\n",
    "check_rank(x_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose variables to include in fixed effects model\n",
    "x_diff = x_diff[:, 1:5]\n",
    "label_x_fd = label_x[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate FE OLS using the demeaned variables.\n",
    "fd_result = lm.estimate(y_diff, x_diff, transform='fd', N=N, T=T-1)\n",
    "\n",
    "# Print results\n",
    "lm.print_table((label_y, label_x_fd), fd_result, title='FD regression', floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make function to calculate the serial correlation\n",
    "def serial_corr(y, x, T):\n",
    "    # Calculate the residuals\n",
    "    b_hat = lm.est_ols(y, x)\n",
    "    e = y - x@b_hat\n",
    "    \n",
    "    # Create a lag transformation matrix\n",
    "    L_T = np.eye(T, k=-1)\n",
    "    L_T = L_T[1:]\n",
    "\n",
    "    # Lag residuals\n",
    "    e_l = lm.perm(L_T, e)\n",
    "\n",
    "    # Create a transformation matrix that removes the first observation of each individual\n",
    "    I_T = np.eye(T, k=0)\n",
    "    I_T = I_T[1:]\n",
    "    \n",
    "    # Remove first observation of each individual\n",
    "    e = lm.perm(I_T, e)\n",
    "    \n",
    "    # Calculate the serial correlation\n",
    "    return lm.estimate(e, e_l,N=N,T=T-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate serial correlation\n",
    "corr_result = serial_corr(y_diff, x_diff, T-1)\n",
    "\n",
    "# Print results\n",
    "label_ye = 'OLS residual, e\\u1d62\\u209c'\n",
    "label_e = ['e\\u1d62\\u209c\\u208B\\u2081']\n",
    "lm.print_table(\n",
    "    (label_ye, label_e), corr_result, \n",
    "    title='Serial Correlation', floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead employment\n",
    "F_T = np.eye(T, k=1)\n",
    "F_T = F_T[:-1]\n",
    "\n",
    "employment_lead = lm.perm(F_T, x[:, 1].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last observed year for every individual\n",
    "I_T = np.eye(T, k=0)\n",
    "I_T = I_T[:-1]\n",
    "\n",
    "x_exo = lm.perm(I_T, x)\n",
    "y_exo = lm.perm(I_T, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add employment_lead to x_exo\n",
    "x_exo = np.hstack((x_exo, employment_lead))\n",
    "\n",
    "# Within transform the data\n",
    "Q_T = demeaning_matrix(T - 1)\n",
    "yw_exo = lm.perm(Q_T, y_exo)\n",
    "xw_exo = lm.perm(Q_T, x_exo)\n",
    "\n",
    "# Select variables\n",
    "xw_exo = np.hstack((xw_exo[:, 1:5], xw_exo[:, -1].reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate model\n",
    "exo_test = lm.estimate(yw_exo, xw_exo, N=N, T=T - 1, transform='fe')\n",
    "\n",
    "# Print results\n",
    "label_exo = label_x_fe + ['Employment lead']\n",
    "lm.print_table((label_y, label_exo), exo_test, title='Exogeneity test', floatfmt='.4f')\n",
    "print(\"Critical value (5%):\", crit_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lead of employment\n",
    "F_T = np.eye(T, k=1)[:-1]  # shifts forward, drops last row\n",
    "employment_lead = lm.perm(F_T, x[:, 2].reshape(-1, 1))  # employment is column 2\n",
    "\n",
    "# Drop last year for everyone (so dimensions match)\n",
    "I_T = np.eye(T)[:-1]\n",
    "x_exo = lm.perm(I_T, x)\n",
    "y_exo = lm.perm(I_T, y)  # <-- now y is ldsa\n",
    "\n",
    "# Add employment_lead to regressors\n",
    "x_exo = np.hstack((x_exo, employment_lead))\n",
    "\n",
    "# Within transform (demean)\n",
    "Q_T = demeaning_matrix(T - 1)\n",
    "yw_exo = lm.perm(Q_T, y_exo)\n",
    "xw_exo = lm.perm(Q_T, x_exo)\n",
    "\n",
    "# Keep the usual regressors + the lead\n",
    "xw_exo = np.hstack((xw_exo[:, 1:3], xw_exo[:, -1].reshape(-1, 1)))  \n",
    "# columns: capital, employment, lead employment\n",
    "\n",
    "# Estimate FE model with the lead\n",
    "exo_test = lm.estimate(yw_exo, xw_exo, N=N, T=T-1, transform='fe')\n",
    "\n",
    "# Print results\n",
    "label_exo = [\"Capital\", \"Employment\", \"Lead employment\"]\n",
    "lm.print_table((\"Output (ldsa)\", label_exo), exo_test, title=\"Strict exogeneity test on FE\", floatfmt=\".4f\")\n",
    "print(\"Critical value (5%):\", crit_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FD transformation matrix\n",
    "D_T = np.eye(T-1, T, k=1) - np.eye(T-1, T)\n",
    "\n",
    "# Transform y and x with FD\n",
    "y_fd = lm.perm(D_T, y)\n",
    "x_fd = lm.perm(D_T, x)\n",
    "\n",
    "# Create lead of Δemployment (column 2 of x_fd is Δemployment)\n",
    "F_T_fd = np.eye(T-2, T-1, k=1)   # shifts forward in differences\n",
    "employment_lead_fd = lm.perm(F_T_fd, x_fd[:, 2].reshape(-1, 1))\n",
    "\n",
    "# Drop last FD observation for alignment\n",
    "I_T_fd = np.eye(T-1)[:-1]\n",
    "x_fd_exo = lm.perm(I_T_fd, x_fd)\n",
    "y_fd_exo = lm.perm(I_T_fd, y_fd)\n",
    "\n",
    "# Add lead of Δemployment\n",
    "x_fd_exo = np.hstack((x_fd_exo, employment_lead_fd))\n",
    "\n",
    "# Keep same regressors: Δcapital, Δemployment, Δemployment_lead\n",
    "x_fd_exo = np.hstack((x_fd_exo[:, 1:3], x_fd_exo[:, -1].reshape(-1, 1)))\n",
    "\n",
    "# Estimate FD model\n",
    "exo_test_fd = lm.estimate(y_fd_exo, x_fd_exo, N=N, T=T-2, transform=\"fd\")\n",
    "\n",
    "# Print results\n",
    "labels_fd = [\"ΔCapital\", \"ΔEmployment\", \"Lead ΔEmployment\"]\n",
    "lm.print_table((\"ΔOutput (ldsa)\", labels_fd), exo_test_fd,\n",
    "               title=\"Strict Exogeneity Test (FD)\", floatfmt=\".4f\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD Exogeneity Test (lead-variable)\n",
      "Model: Δ log y_it = b1 Δ log K_it + b2 Δ log L_it + b3 Δ log L_{i,t+1} + Δu_it\n",
      "\n",
      "              Variable        Beta          SE         t\n",
      "                 const     -0.0000      0.0035     -0.01\n",
      "          Δlog Capital      0.0753      0.0345      2.18\n",
      "       Δlog Employment     -0.0015      0.0241     -0.06\n",
      "  Lead Δlog Employment      0.0338      0.0192      1.76\n",
      "\n",
      "Test H0: b3 (Lead term) = 0 → t=1.76, p=0.08036 (df clustered=141)\n",
      "→ Do NOT reject exogeneity in FD.\n"
     ]
    }
   ],
   "source": [
    "from w3_LinearModels import fd_exogeneity_lead_test\n",
    "\n",
    "\n",
    "# FD test in log differences (assignment style)\n",
    "fd_exogeneity_lead_test(y, x, N, T, cap_col=1, emp_col=2, logs=True, drop_zeros=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ef42839c56fd8bee084dafb278faf4416bb17c87278e59e0e4bb5f7c8f27c505"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
