{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 2\n",
    "Before we start working on some exercises we will briefly introduce two concepts in Python. First, importing and exporting data. Second, using functions. If you are already familiar\n",
    "with these features, you can skip the next two sections and jump directly to the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import all necessary packages. We have made a .py file that we will use as a \"toolbox\". We will fill this toolbox with functions, that we will use as we progress through the course. Exactly how you structure this toolbox is up to you (if you i.e. want to turn it into a class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from tabulate import tabulate\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#Supress Future Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Import this weeks LinearModels.py file\n",
    "import w2_LinearModels_ante as lm\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and exporting data in Python\n",
    "The easiest way to import data into an numpy array is using a .txt file. Normally we specify a path to the text file, but we will create a fake one to illustrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake file looks like this: \n",
      " 0 1\n",
      " 2 3\n",
      "\n",
      "Loaded into a numpy array, we get the following <class 'numpy.ndarray'>: \n",
      " [[0. 1.]\n",
      " [2. 3.]]\n"
     ]
    }
   ],
   "source": [
    "# Create a fake file for easy use.\n",
    "fake_file = StringIO(\"0 1\\n 2 3\")\n",
    "print(f\"Fake file looks like this: \\n {fake_file.getvalue()}\")\n",
    "print()\n",
    "\n",
    "# Load the fake txt file into a numpy array.\n",
    "data = np.loadtxt(fake_file)\n",
    "print(f'Loaded into a numpy array, we get the following {type(data)}: \\n {data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, there is no direct way to load an excel sheet into numpy. The easiest solution is to use pandas as an intermediate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "# We save the fake file we created earlier as an excel file, \n",
    "# so that we can illustrate how to import using excel.\n",
    "to_export = pd.DataFrame(data)\n",
    "to_export.to_excel('test_file.xlsx', header=None, index=None)\n",
    "\n",
    "# Its important to note that Pandas will treat the first row as a header. If there is no header,\n",
    "# this needs to be specified. There are also alot of extra options to load specific sheets, or\n",
    "# only parts of the sheets and tons of extra options.\n",
    "df_import = pd.read_excel('test_file.xlsx', header=None)\n",
    "np_array = df_import.to_numpy()\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Data\n",
    "To save a numpy array as a .txt file is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('real_file.txt', np_array)\n",
    "#print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If one has large numpy arrays and wants to store them efficiently, they can be saved as a binary .npy files. Such files are not compatible with other programs.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises \n",
    "### Import data\n",
    "\n",
    "The exercise takes up the union membership example from the cover sheet. The data set WAGEPAN.TXT contains information about 545 men who worked every year from 1980 to 1987 in the US. The variables of interest are\n",
    "\n",
    "\n",
    "| Variable | Content |\n",
    "|-|-|\n",
    "| nr | Variable that identifies the individual  |\n",
    "| year | Year of observation |\n",
    "| Black | Black |\n",
    "| Exper | Years since left school |\n",
    "| Hisp | Hispanic |\n",
    "| Married | Marital status |\n",
    "| Educ | Years of schooling |\n",
    "| Union | Union membership |\n",
    "| Lwage | Natural logarithm of hourly wages |\n",
    "| Expersq | Exper2 |\n",
    "\n",
    "Consider the following wage equation:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log\\left(wage_{it}\\right) & =\\beta_{0}+\\beta_{1}\\textit{exper}_{it}+\\beta_{2}\\textit{exper}_{it}^{2}+\\beta_{3}\\textit{union}_{it}+\\beta_{4}\\textit{married}_{i} +\\beta_{5}\\textit{educ}_{i}+\\beta_{6}\\textit{hisp}_{i}+\\beta_{7}\\textit{black}_{i}+c_{i}+u_{it} \\tag{1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Note that *educ*, *hisp*, and *black* are time-invariant variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has 10 columns. Named from 0 to 9. Here is a variable describtion:\n",
    "- Column 0: ID\n",
    "- Column 1: Year\n",
    "- Column 2: Black\n",
    "- Column 3: Experience\n",
    "- Column 4: Hispanic\n",
    "- Column 5: Married\n",
    "- Column 6: Education\n",
    "- Column 7: Union\n",
    "- Column 8: ln wage\n",
    "- Column 9: Experience sqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by loading the data. Some of this has been done for you already. Since we are working with panels, we need to know how many persons there are and how many time periods we observe them. Since we operate using a balanced panel, this makes our life a little easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 545 persons, each observed 7 times, over the years 1980 to 1987\n"
     ]
    }
   ],
   "source": [
    "# First, import the data into numpy. \n",
    "# Data should load the wagepan.txt file.\n",
    "data = np.loadtxt('wagepan.txt', delimiter=\",\", skiprows=1)\n",
    "id_array = np.array(data[:, 0])\n",
    "\n",
    "# Count how many persons we have. This returns a tuple with the unique IDs,\n",
    "# and the number of times each person is observed.\n",
    "unique_id = np.unique(id_array, return_counts=True)\n",
    "N = unique_id[0].size\n",
    "T = int(unique_id[1].mean())\n",
    "year = np.array(data[:, 1], dtype=int)\n",
    "print(f'We have {N} persons, each observed {T} times, over the years {year.min()} to {year.max()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the rest of the data into arrays.\n",
    "y = data[:, 8]  # Log wage is column 8\n",
    "\n",
    "# x needs to have a constant vector in the first row. How would you add this? \n",
    "# Note that the order is set to match the order of variables in the model.\n",
    "x = np.column_stack([\n",
    "    np.ones(y.shape[0]),  # Constant\n",
    "    data[:, 3],    # Experience\n",
    "    data[:, 9],    # Experience sqr\n",
    "    data[:, 7],    # Union\n",
    "    data[:, 5],    # Married\n",
    "    data[:, 6],    # Education\n",
    "    data[:, 4],    # Hispanic\n",
    "    data[:, 2]     # Black\n",
    "])\n",
    "\n",
    "# Lets also make some variable names\n",
    "label_y = 'Log wage'\n",
    "label_x = [\n",
    "    'Constant', \n",
    "    'Experience', \n",
    "    'Experience sqr', \n",
    "    'Union',\n",
    "    'Married', \n",
    "    'Education', \n",
    "    'Hispanic', \n",
    "    'Black', \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooled OLS (POLS) Estimator\n",
    "- **Estimate (1) by pooled OLS,** thus considering for the moment the unobserved components of (q) as one (composite) error term $v_{it}=c_{i}+u_{it}$. \n",
    "- Fill in the remaining parts of the function est_ols() in the accompanying python file (LinearModelsWeek2_ante.py) to estimate the model.\n",
    "- What assumptions are made about $E\\left[c_{i}\\mathbf{x}_{it}\\right]$ and $E\\left[u_{it}\\mathbf{x}_{it}\\right]$ when justifying this estimation approach? (Hint: See Wooldridge p. 283)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant        : -0.0344\n",
      "Experience      :  0.0889\n",
      "Experience sqr  : -0.0028\n",
      "Union           :  0.1800\n",
      "Married         :  0.1076\n",
      "Education       :  0.0994\n",
      "Hispanic        :  0.0156\n",
      "Black           : -0.1439\n"
     ]
    }
   ],
   "source": [
    "# Define a simple OLS estimator\n",
    "def est_ols(x, y):\n",
    "    # Ensure y is a column vector\n",
    "    y = y.reshape(-1, 1)\n",
    "    # OLS estimator: (X'X)^{-1} X'y\n",
    "    b_hat = np.linalg.inv(x.T @ x) @ (x.T @ y)\n",
    "    return b_hat\n",
    "\n",
    "# Estimate coefficients\n",
    "b_hat = est_ols(x, y)\n",
    "\n",
    "# Print the results\n",
    "for label, b_k in zip(label_x, b_hat):\n",
    "    print(f'{label:16}: {b_k[0]:7.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the standard errors of the coefficients. This is very similar to previous week's exercise. (Hint: See Wooldridge p. 59-60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant        : -0.0344    (5.1491)\n",
      "Experience      :  0.0889    (0.8071)\n",
      "Experience sqr  : -0.0028    (0.0565)\n",
      "Union           :  0.1800    (1.3652)\n",
      "Married         :  0.1076    (1.2517)\n",
      "Education       :  0.0994    (0.3731)\n",
      "Hispanic        :  0.0156    (1.6595)\n",
      "Black           : -0.1439    (1.8787)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the residuals\n",
    "resid = y - x @ b_hat\n",
    "\n",
    "# Calculate estimate of variance of residuals\n",
    "SSR = (resid ** 2).sum()\n",
    "K = x.shape[1]\n",
    "sigma = np.sqrt(SSR / (y.size - K))\n",
    "\n",
    "\n",
    "# Calculate the variance-covariance matrix\n",
    "cov = sigma ** 2 * np.linalg.inv(x.T @ x)\n",
    "\n",
    "# Calculate the standard errors \n",
    "# Make sure to output the result in a vector\n",
    "se = np.sqrt(np.diag(cov)).reshape(-1, 1)\n",
    "\n",
    "#Print results\n",
    "for label, b_k, se_k in zip(label_x, b_hat, se):\n",
    "    print(f'{label:16}: {b_k[0]:7.4f}    ({se_k[0]:6.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the functions estimate() and variance() in the accompanying python file. You can reuse most of the code above.\n",
    "\n",
    "Using the function, print_table(), you should reproduce the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled OLS\n",
      "Dependent variable: Log wage\n",
      "\n",
      "                   Beta      Se  t-values\n",
      "--------------  -------  ------  ------------------------------------------------------------------------\n",
      "Constant        -0.0344  0.0646  [-0.53210153  1.37725289 -0.04387665  2.78775511  1.66679944  1.53974474\n",
      "                                   0.24233468 -2.22814073]\n",
      "Experience       0.0889  0.0101  [ -3.3945569    8.78622411  -0.27991233  17.78456333  10.6333946\n",
      "                                    9.8228455    1.54598102 -14.21448737]\n",
      "Experience sqr  -0.0028  0.0007  [ -48.5308704   125.61377408   -4.00181515  254.26008849  152.02216671\n",
      "                                   140.43401121   22.10238532 -203.21987952]\n",
      "Union            0.1800  0.0171  [-2.00686916  5.19443412 -0.16548476 10.51427114  6.28648519  5.80728686\n",
      "                                   0.91398722 -8.40363475]\n",
      "Married          0.1076  0.0157  [-2.18895831  5.66574043 -0.18049968 11.46826194  6.85687651  6.33419911\n",
      "                                   0.99691598 -9.16612129]\n",
      "Education        0.0994  0.0047  [ -7.34412077  19.00898787  -0.60559008  38.47688658  23.00533954\n",
      "                                   21.2517173    3.34472853 -30.7530305 ]\n",
      "Hispanic         0.0156  0.0208  [-1.65097523  4.27326416 -0.13613804  8.64969254  5.1716532   4.77743489\n",
      "                                   0.75190266 -6.91335194]\n",
      "Black           -0.1439  0.0236  [-1.4583864   3.77478126 -0.12025733  7.64069246  4.56837182  4.22013969\n",
      "                                   0.66419205 -6.10689869]\n",
      "R² = 0.187\n",
      "σ² = 0.231\n"
     ]
    }
   ],
   "source": [
    "# Estimate model using OLS\n",
    "ols_result = lm.estimate(y,x)\n",
    "\n",
    "# Print table\n",
    "lm.print_table((label_y, label_x), ols_result, title=\"Pooled OLS\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooled OLS <br>\n",
    "Dependent variable: Log wage <br>\n",
    "\n",
    "|                |    Beta |     Se |   t-values |\n",
    "|----------------|---------|--------|------------|\n",
    "| Constant       | -0.0347 | 0.0646 |    -0.5375 |\n",
    "| Experience     |  0.0892 | 0.0101 |     8.8200 |\n",
    "| Experience sqr | -0.0028 | 0.0007 |    -4.0272 |\n",
    "| Union          |  0.1801 | 0.0171 |    10.5179 |\n",
    "| Married        |  0.1077 | 0.0157 |     6.8592 |\n",
    "| Education      |  0.0994 | 0.0047 |    21.2476 |\n",
    "| Hispanic       |  0.0157 | 0.0208 |     0.7543 |\n",
    "| Black          | -0.1438 | 0.0236 |    -6.1055 |\n",
    "R² = 0.187 <br>\n",
    "σ² = 0.231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed Effects (FE) Estimator\n",
    "In the next step, we will estimate the model using fixed effects. This is done by first performing the fixed effects (within-groups) transformation on the data and then using pooled OLS on the transformed data.\n",
    "We will break this down into multiple steps.\n",
    "\n",
    "### Using numpy\n",
    "Create a transformation matrix with dimensions $T \\times T$ that can be used to transform the data. Note that the matrix will be premultiplied on the data for each individual, so the dimensions will match in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demeaning matrix for T=7 \n",
      " [[ 0.85714286 -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714\n",
      "  -0.14285714]\n",
      " [-0.14285714  0.85714286 -0.14285714 -0.14285714 -0.14285714 -0.14285714\n",
      "  -0.14285714]\n",
      " [-0.14285714 -0.14285714  0.85714286 -0.14285714 -0.14285714 -0.14285714\n",
      "  -0.14285714]\n",
      " [-0.14285714 -0.14285714 -0.14285714  0.85714286 -0.14285714 -0.14285714\n",
      "  -0.14285714]\n",
      " [-0.14285714 -0.14285714 -0.14285714 -0.14285714  0.85714286 -0.14285714\n",
      "  -0.14285714]\n",
      " [-0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714  0.85714286\n",
      "  -0.14285714]\n",
      " [-0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714 -0.14285714\n",
      "   0.85714286]]\n"
     ]
    }
   ],
   "source": [
    "# Create transformation matrix\n",
    "def demeaning_matrix(T):\n",
    "    Q_T = np.eye(T) - np.ones((T, T)) / T\n",
    "    return Q_T\n",
    "\n",
    "# Print the matrix\n",
    "Q_T = demeaning_matrix(T)\n",
    "print(f'Demeaning matrix for T={T} \\n', Q_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the supplied perm() function to apply the transformation to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Data is not balanced. Cannot reshape to (N, T). Using original arrays.\n",
      "[[  1.   2.   4. ...  14.   0.   0.]\n",
      " [  1.   3.   9. ...  14.   0.   0.]\n",
      " [  1.   4.  16. ...  14.   0.   0.]\n",
      " ...\n",
      " [  1.  10. 100. ...   9.   0.   0.]\n",
      " [  1.  11. 121. ...   9.   0.   0.]\n",
      " [  1.  12. 144. ...   9.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "# Transform the data\n",
    "# Reshape y and x to (N, T) and (N, T, K) respectively, then transpose to (T, N) for Q_T multiplication\n",
    "# Check if y and x can be reshaped to (N, T)\n",
    "if y.size == N * T and x.shape[0] == N * T:\n",
    "\ty_reshaped = y.reshape(N, T).T  # shape (T, N)\n",
    "\ty_demean = (Q_T @ y_reshaped).T.reshape(-1, 1)  # shape (N*T, 1)\n",
    "\n",
    "\tx_reshaped = x.reshape(N, T, K).transpose(1, 0, 2)  # shape (T, N, K)\n",
    "\tx_demean = (Q_T @ x_reshaped.reshape(T, -1)).reshape(T, N, K).transpose(1, 0, 2).reshape(-1, K)  # shape (N*T, K)\n",
    "else:\n",
    "\t# If not, use the original arrays (no reshaping)\n",
    "\tprint(\"Warning: Data is not balanced. Cannot reshape to (N, T). Using original arrays.\")\n",
    "\ty_demean = y.reshape(-1, 1)\n",
    "\tx_demean = x\n",
    "\n",
    "#print x_demean\n",
    "print(x_demean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the rank and eigenvalues of the within transformed $\\mathbf{X}$ matrix? Why?\n",
    "\n",
    "What happens to *educ, hisp, and black* and the constant when the data are within transformed? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of demeaned x: 8\n",
      "Eigenvalues of within-transformed x: [18878951.   296547.     2563.       55.      381.      611.      986.\n",
      "      814.]\n"
     ]
    }
   ],
   "source": [
    "# Create function to check rank of demeaned matrix, and return its eigenvalues.\n",
    "def check_rank(x):\n",
    "    print(f'Rank of demeaned x: {la.matrix_rank(x)}')\n",
    "    lambdas, V = la.eig(x.T@x)\n",
    "    np.set_printoptions(suppress=True)  # This is just to print nicely.\n",
    "    print(f'Eigenvalues of within-transformed x: {lambdas.round(decimals=0)}')\n",
    "\n",
    "# Check rank of demeaned x\n",
    "check_rank(x_demean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust `x_demean` such that the model can be estimated using the FE estimator. Adjust the labels to match with `x_demean`.\n",
    "\n",
    "Estimate the model using the estimate() function, and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose variables to include in fixed effects model\n",
    "x_demean = x_demean[:, [0,1,2,5,6,7]]  # Constant, Exp, Exp^2, Educ, Hisp, Black\n",
    "label_x_fe = ['Constant', 'Exp', 'Exp^2', 'Educ', 'Hisp', 'Black']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FE regression\n",
      "Dependent variable: Log wage\n",
      "\n",
      "             Beta      Se    t-values\n",
      "--------  -------  ------  ----------\n",
      "Constant  -0.0539  0.0654     -0.8247\n",
      "Exp        0.1066  0.0102     10.5026\n",
      "Exp^2     -0.0037  0.0007     -5.0888\n",
      "Educ       0.1024  0.0047     21.5977\n",
      "Hisp       0.0250  0.0212      1.1830\n",
      "Black     -0.1405  0.0236     -5.9655\n",
      "R² = 0.155\n",
      "σ² = 0.240\n"
     ]
    }
   ],
   "source": [
    "# Estimate FE OLS using the demeaned variables.\n",
    "fe_result = lm.estimate(y_demean, x_demean, N=N, T=T)\n",
    "\n",
    "# Print results\n",
    "lm.print_table((label_y, label_x_fe), fe_result, title='FE regression', floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a table that looks like this:\n",
    "\n",
    "FE regression<br>\n",
    "Dependent variable: Log wage\n",
    "\n",
    "|                |    Beta |     Se |   t-values |\n",
    "|----------------|---------|--------|------------|\n",
    "| Experience     |  0.1168 | 0.0084 |    13.8778 |\n",
    "| Experience sqr | -0.0043 | 0.0006 |    -7.1057 |\n",
    "| Union          |  0.0821 | 0.0193 |     4.2553 |\n",
    "| Married        |  0.0453 | 0.0183 |     2.4743 |\n",
    "R² = 0.178 <br>\n",
    "σ² = 0.123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** Did you use the right standard errors? If not, implement the correct standard errors in the variance() function, and try again. (Hint: see Wooldridge p.306)\n",
    "\n",
    "How big is the union premium according to the estimate from the FE model? Compare this with the estimate that you calculated from the pooled OLS regression. What does this suggest about $E\\left[union_{it}c_{i}\\right]$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pandas\n",
    "An alternative to the perm function is to use panda dataframes to group the data. This has been done for the *entire* dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data using pandas\n",
    "pddat = pd.read_csv('wagepan.txt', delimiter=\",\", header=None)\n",
    "pddat.columns = [\"ID\", \"year\", \"black\", \"exp\", \"hisp\", \"mar\", \"educ\", \"union\", \"logwage\", \"expsq\"]\n",
    "\n",
    "# Rearrange the data\n",
    "desired_order = [\"ID\", \"year\", \"logwage\", \"exp\", \"expsq\", \"union\", \"mar\", \"educ\", \"hisp\", \"black\"]\n",
    "pddat = pddat[desired_order] # reorder columns\n",
    "\n",
    "# Sort the data (it's important to ensure years are sorted correctly when transforming the data)\n",
    "pddat = pddat.sort_values([\"ID\", \"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demean data\n",
    "pddat_demean = pddat - pddat.groupby(\"ID\").transform('mean')\n",
    "\n",
    "# reorder columns\n",
    "# The order changes back to the original order after the transformation, due to the way pandas works.\n",
    "pddat_demean = pddat_demean[desired_order] \n",
    "\n",
    "# turn into numpy array\n",
    "datdemean = pddat_demean.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data. Select the variables that you need to estimate the model using FE. Estimate the model. Did you get the same results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "year",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "logwage",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "exp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "expsq",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "union",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mar",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "educ",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hisp",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "black",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "456ebcb6-6612-4fb4-8ecd-aa19471ec4d6",
       "rows": [
        [
         "0",
         null,
         "-3.5",
         "-0.05811191350221634",
         "-3.5",
         "-24.5",
         "-0.125",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "1",
         null,
         "-2.5",
         "0.5974079295992851",
         "-2.5",
         "-21.5",
         "0.875",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "2",
         null,
         "-1.5",
         "0.08880960196256638",
         "-1.5",
         "-16.5",
         "-0.125",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "3",
         null,
         "-0.5",
         "0.1775612756609919",
         "-0.5",
         "-9.5",
         "-0.125",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "4",
         null,
         "0.5",
         "0.3124730512499809",
         "0.5",
         "-0.5",
         "-0.125",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "5",
         null,
         "1.5",
         "0.44423889368772507",
         "1.5",
         "10.5",
         "-0.125",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "6",
         null,
         "2.5",
         "-1.9759146645665169",
         "2.5",
         "23.5",
         "-0.125",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "7",
         null,
         "3.5",
         "0.41353582590818405",
         "3.5",
         "38.5",
         "-0.125",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "8",
         null,
         "-3.5",
         "0.038176074624061584",
         "-3.5",
         "-45.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "9",
         null,
         "-2.5",
         "-0.11938820779323578",
         "-2.5",
         "-36.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "10",
         null,
         "-1.5",
         "-0.07859586179256439",
         "-1.5",
         "-25.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "11",
         null,
         "-0.5",
         "0.087623730301857",
         "-0.5",
         "-12.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "12",
         null,
         "0.5",
         "-0.015764102339744568",
         "0.5",
         "2.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "13",
         null,
         "1.5",
         "-0.02919815480709076",
         "1.5",
         "19.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "14",
         null,
         "2.5",
         "-0.06540094316005729",
         "2.5",
         "38.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "15",
         null,
         "3.5",
         "0.182547464966774",
         "3.5",
         "59.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "16",
         null,
         "-3.5",
         "-0.5184242129325867",
         "-3.5",
         "-45.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "17",
         null,
         "-2.5",
         "-0.2990078330039978",
         "-2.5",
         "-36.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "18",
         null,
         "-1.5",
         "-0.40264326333999634",
         "-1.5",
         "-25.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "19",
         null,
         "-0.5",
         "-0.03615814447402954",
         "-0.5",
         "-12.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "20",
         null,
         "0.5",
         "0.14962738752365112",
         "0.5",
         "2.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "21",
         null,
         "1.5",
         "0.23227518796920776",
         "1.5",
         "19.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "22",
         null,
         "2.5",
         "0.03555697202682495",
         "2.5",
         "38.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "23",
         null,
         "3.5",
         "0.8387739062309265",
         "3.5",
         "59.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "24",
         null,
         "-3.5",
         "0.12045134603977226",
         "-3.5",
         "-31.5",
         "0.75",
         "-0.125",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "25",
         null,
         "-2.5",
         "-0.3025042861700058",
         "-2.5",
         "-26.5",
         "0.75",
         "-0.125",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "26",
         null,
         "-1.5",
         "-0.30016611516475655",
         "-1.5",
         "-19.5",
         "-0.25",
         "-0.125",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "27",
         null,
         "-0.5",
         "-0.03274939954280853",
         "-0.5",
         "-10.5",
         "-0.25",
         "-0.125",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "28",
         null,
         "0.5",
         "0.04955007135868095",
         "0.5",
         "0.5",
         "-0.25",
         "-0.125",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "29",
         null,
         "1.5",
         "0.13460923731327057",
         "1.5",
         "13.5",
         "-0.25",
         "-0.125",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "30",
         null,
         "2.5",
         "-0.031216248869895935",
         "2.5",
         "28.5",
         "-0.25",
         "-0.125",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "31",
         null,
         "3.5",
         "0.3620253950357437",
         "3.5",
         "45.5",
         "-0.25",
         "0.875",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "32",
         null,
         "-3.5",
         "-0.10635437071323395",
         "-3.5",
         "-52.5",
         "0.875",
         "-0.5",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "33",
         null,
         "-2.5",
         "-0.09286989271640778",
         "-2.5",
         "-41.5",
         "-0.125",
         "-0.5",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "34",
         null,
         "-1.5",
         "-0.09183241426944733",
         "-1.5",
         "-28.5",
         "-0.125",
         "-0.5",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "35",
         null,
         "-0.5",
         "0.14738641679286957",
         "-0.5",
         "-13.5",
         "-0.125",
         "-0.5",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "36",
         null,
         "0.5",
         "0.0798250287771225",
         "0.5",
         "3.5",
         "-0.125",
         "0.5",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "37",
         null,
         "1.5",
         "0.07069359719753265",
         "1.5",
         "22.5",
         "-0.125",
         "0.5",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "38",
         null,
         "2.5",
         "-0.06411255896091483",
         "2.5",
         "43.5",
         "-0.125",
         "0.5",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "39",
         null,
         "3.5",
         "0.05726419389247894",
         "3.5",
         "66.5",
         "-0.125",
         "0.5",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "40",
         null,
         "-3.5",
         "-1.1745491996407509",
         "-3.5",
         "-31.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "41",
         null,
         "-2.5",
         "-0.11313239485025406",
         "-2.5",
         "-26.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "42",
         null,
         "-1.5",
         "0.028981171548366547",
         "-1.5",
         "-19.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "43",
         null,
         "-0.5",
         "-0.1128172054886818",
         "-0.5",
         "-10.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "44",
         null,
         "0.5",
         "0.2705424651503565",
         "0.5",
         "0.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "45",
         null,
         "1.5",
         "0.01269908994436264",
         "1.5",
         "13.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "46",
         null,
         "2.5",
         "0.37325998395681403",
         "2.5",
         "28.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "47",
         null,
         "3.5",
         "0.7150160893797874",
         "3.5",
         "45.5",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "48",
         null,
         "-3.5",
         "-0.2567909508943558",
         "-3.5",
         "-31.5",
         "0.0",
         "-0.375",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "49",
         null,
         "-2.5",
         "-0.00447554886341095",
         "-2.5",
         "-26.5",
         "0.0",
         "-0.375",
         "0.0",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 4360
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>year</th>\n",
       "      <th>logwage</th>\n",
       "      <th>exp</th>\n",
       "      <th>expsq</th>\n",
       "      <th>union</th>\n",
       "      <th>mar</th>\n",
       "      <th>educ</th>\n",
       "      <th>hisp</th>\n",
       "      <th>black</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-0.058112</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-24.5</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>0.597408</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-21.5</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.088810</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-16.5</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.177561</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.312473</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.209697</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-13.5</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4356</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.169639</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4357</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.383780</td>\n",
       "      <td>1.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.363713</td>\n",
       "      <td>2.5</td>\n",
       "      <td>43.5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4359</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.084362</td>\n",
       "      <td>3.5</td>\n",
       "      <td>66.5</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4360 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  year   logwage  exp  expsq  union    mar  educ  hisp  black\n",
       "0    NaN  -3.5 -0.058112 -3.5  -24.5 -0.125  0.000   0.0   0.0    0.0\n",
       "1    NaN  -2.5  0.597408 -2.5  -21.5  0.875  0.000   0.0   0.0    0.0\n",
       "2    NaN  -1.5  0.088810 -1.5  -16.5 -0.125  0.000   0.0   0.0    0.0\n",
       "3    NaN  -0.5  0.177561 -0.5   -9.5 -0.125  0.000   0.0   0.0    0.0\n",
       "4    NaN   0.5  0.312473  0.5   -0.5 -0.125  0.000   0.0   0.0    0.0\n",
       "...   ..   ...       ...  ...    ...    ...    ...   ...   ...    ...\n",
       "4355 NaN  -0.5  0.209697 -0.5  -13.5 -0.375  0.375   0.0   0.0    0.0\n",
       "4356 NaN   0.5 -0.169639  0.5    3.5  0.625  0.375   0.0   0.0    0.0\n",
       "4357 NaN   1.5  0.383780  1.5   22.5 -0.375  0.375   0.0   0.0    0.0\n",
       "4358 NaN   2.5  0.363713  2.5   43.5  0.625  0.375   0.0   0.0    0.0\n",
       "4359 NaN   3.5  0.084362  3.5   66.5  0.625  0.375   0.0   0.0    0.0\n",
       "\n",
       "[4360 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at data\n",
    "pddat_demean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select variables\n",
    "# Turn the data into numpy arrays\n",
    "y_dot = y_demean.flatten()\n",
    "x_dot = x_demean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FE regression\n",
      "Dependent variable: Log wage\n",
      "\n",
      "             Beta      Se  t-values\n",
      "--------  -------  ------  -------------------------------------------------------------------------\n",
      "Constant  -0.0539  0.0755  [-0.71413096  1.41149778 -0.04836546  1.35611682  0.33165461 -1.86066561]\n",
      "Exp        0.1066  0.0117  [ -4.60124201   9.09447043  -0.31162515   8.73764345   2.13689534\n",
      "                            -11.98851931]\n",
      "Exp^2     -0.0037  0.0008  [ -65.06384775  128.60032971   -4.40653437  123.55461888   30.2167617\n",
      "                            -169.52361851]\n",
      "Educ       0.1024  0.0055  [ -9.84845685  19.46572239  -0.66699965  18.70197313   4.5737915\n",
      "                            -25.66011847]\n",
      "Hisp       0.0250  0.0245  [-2.20574828  4.35971688 -0.14938719  4.18866079  1.02438716 -5.74706911]\n",
      "Black     -0.1405  0.0272  [-1.98260574  3.91867005 -0.13427457  3.76491869  0.92075595 -5.16567204]\n",
      "R² = 0.155\n",
      "σ² = 0.320\n"
     ]
    }
   ],
   "source": [
    "# Estimate using the demeaned variables, y_dot and x_dot\n",
    "fe_result = lm.estimate(y_dot, x_dot, transform='fe', N=N, T=T)\n",
    "\n",
    "# Print results\n",
    "lm.print_table((label_y, label_x_fe), fe_result, title='FE regression', floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First-difference (FD) Estimator\n",
    "Construct $\\mathbf{D}$ and use the procedure `perm` $(\\mathbf{D},\\mathbf{x})$ to compute first differences of the elements of $\\mathbf{y}$ and $\\mathbf{x}$. $\\mathbf{D}$ should be a $(T-1) \\times T$ matrix. Why?\n",
    "\n",
    "What happens to *educ, hisp* and *black* and the constant when the data are transformed into first differences? What is the rank of the first differenced $\\mathbf{x}$-matrix? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First differening matrix for T=7 \n",
      " [[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Create transformation matrix\n",
    "def fd_matrix(T):\n",
    "    D_T = np.zeros((T-1, T))\n",
    "    return D_T\n",
    "\n",
    "# Print the matrix\n",
    "D_T = fd_matrix(T)\n",
    "print(f'First differening matrix for T={T} \\n', D_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4359 into shape (545,7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Transform the data.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m y_diff \u001b[38;5;241m=\u001b[39m D_T \u001b[38;5;241m@\u001b[39m y\u001b[38;5;241m.\u001b[39mreshape(N, T)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      3\u001b[0m x_diff \u001b[38;5;241m=\u001b[39m D_T \u001b[38;5;241m@\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(N, T, K)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(T, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Print x_diff\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 4359 into shape (545,7)"
     ]
    }
   ],
   "source": [
    "# Transform the data.\n",
    "y_diff = # Fill in\n",
    "x_diff = # Fill in\n",
    "\n",
    "# Print x_diff\n",
    "print(x_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check rank condition.\n",
    "check_rank(x_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust `x_diff` such that the model can be estimated using the FD estimator. Adjust the labels to match with `x_diff`.\n",
    "\n",
    "Estimate the model using the estimate() function, and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose variables to include in fixed effects model\n",
    "x_diff = # Fill in\n",
    "label_x_fd = # Fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate FE OLS using the demeaned variables.\n",
    "fd_result = # Fill in\n",
    "\n",
    "# Print results\n",
    "lm.print_table((label_y, label_x_fd), fd_result, title='FD regression', floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a table that looks like this:\n",
    "\n",
    "FD regression <br>\n",
    "Dependent variable: Log wage\n",
    "\n",
    "|                |    Beta |     Se |   t-values |\n",
    "|----------------|---------|--------|------------|\n",
    "| Experience     |  0.1158 | 0.0196 |     5.9096 |\n",
    "| Experience sqr | -0.0039 | 0.0014 |    -2.8005 |\n",
    "| Union          |  0.0428 | 0.0197 |     2.1767 |\n",
    "| Married        |  0.0381 | 0.0229 |     1.6633 |\n",
    "R² = 0.004 <br>\n",
    "σ² = 0.196\n",
    "\n",
    "**NB:** Did you use the right standard errors? Did you use the right number of time periods in the estimate() function?\n",
    "\n",
    "How big is the union premium according to the estimate from this model? Compare the FD estimate with the estimate that you calculated from the FE regression. Is there a difference? If yes, what (if anything) can we conclude based on this finding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first difference the data\n",
    "pddat_diff = pddat.groupby(\"ID\").diff().dropna() # groupby ID and take difference\n",
    "pddat_diff = pddat_diff[desired_order[1:]] # reorder columns\n",
    "datdiff = pddat_diff.to_numpy() # turn into numpy array\n",
    "\n",
    "# Look at data\n",
    "pddat_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select variables\n",
    "y_delta = pddat_diff['logwage'].to_numpy().reshape(-1,1)\n",
    "x_delta = pddat_diff[['exp','expsq','union','mar']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate using the first differenced variables, y_delta and x_delta. \n",
    "fd_result = # Fill in\n",
    "\n",
    "#print results\n",
    "lm.print_table((label_y, label_x[1:5]), fd_result, title=\"First Differences\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "### Test for serial correlation in the errors using an auxilliary AR(1) model\n",
    "Tests assumption FD.3, where the errors $e_{it} = \\Delta u_{it}$ should be serially uncorrelated.\n",
    "\n",
    "We can easily test this assumption given the OLS residuals from the FD version of equation (1). Run the regression (note that you will lose data for\n",
    "the first *two* periods)\n",
    "\\begin{equation}\n",
    "\\hat{e}_{it}=\\rho\\hat{e}_{it-1}+error_{it},\\quad t=\\color{red}{3},\\dotsc,T,\\quad i=1,\\dotsc,N\\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "Do you find any evidence of serial correlation? Does FD.3 seem appropriate? Why don't we include an intercept in this auxilliary equation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* Under FE.3, the idiosyncratic errors $u_{it}$\n",
    "are uncorrelated. However, FE.3 implies that the $e_{it}$'s are autocorrelated. In fact, of the $u_{it}$'s are serially uncorrelated to begin with, corr $\\left(e_{it},e_{it-1}\\right)=-0.5$. (Check!) This test is of course only valid if the explanatory variables are strictly exogenous!\n",
    "\n",
    "*Hint:* You can use the `perm` function to lag\n",
    "the error term variable. Consider the following; \n",
    "\n",
    "$$\n",
    "{\\begin{bmatrix}\n",
    "1 & 0 & 0 & \\cdots & 0 & 0\\\\\n",
    "0 & 1 & 0 & \\cdots & 0 & 0\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots\\\\\n",
    "0 & 0 & 0 & \\cdots & 1 & 0\n",
    "\\end{bmatrix}}_{T-1\\times T}\\times{\\begin{bmatrix}y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "\\vdots\\\\\n",
    "y_{T}\n",
    "\\end{bmatrix}}_{T \\times 1}={\\begin{bmatrix}y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "\\vdots\\\\\n",
    "y_{T - 1}\n",
    "\\end{bmatrix}}_{T - 1\\times 1}\n",
    "$$\n",
    "\n",
    "*Hint:* You can use the `perm` function to remove the first time-period in the residual. Consider the following; \n",
    "\n",
    "$$\n",
    "{\\begin{bmatrix}\n",
    "0 & 1 & 0 & \\cdots & 0 & 0\\\\\n",
    "0 & 0 & 1 & \\cdots & 0 & 0\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots\\\\\n",
    "0 & 0 & 0 & \\cdots & 0 & 1\n",
    "\\end{bmatrix}}_{T-1\\times T}\\times{\\begin{bmatrix}y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "\\vdots\\\\\n",
    "y_{T}\n",
    "\\end{bmatrix}}_{T \\times 1}={\\begin{bmatrix}y_{2}\\\\\n",
    "y_{3}\\\\\n",
    "\\vdots\\\\\n",
    "y_{T}\n",
    "\\end{bmatrix}}_{T - 1\\times 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make function to calculate the serial correlation\n",
    "def serial_corr(y, x, T):\n",
    "    # Calculate the residuals\n",
    "    b_hat = # Fill in\n",
    "    e = # Fill in\n",
    "    \n",
    "    # Create a lag transformation matrix\n",
    "    L_T = # Fill in\n",
    "    \n",
    "    # Lag residuals\n",
    "    e_l = # Fill in\n",
    "\n",
    "    # Create a transformation matrix that removes the first observation of each individual\n",
    "    I_T = # Fill in \n",
    "    \n",
    "    # Remove first observation of each individual\n",
    "    e = # Fill in\n",
    "    \n",
    "    # Calculate the serial correlation\n",
    "    return lm.estimate( #Fill in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate serial correlation\n",
    "corr_result = serial_corr(y_diff, x_diff, T-1)\n",
    "\n",
    "# Print results\n",
    "label_ye = 'OLS residual, e\\u1d62\\u209c'\n",
    "label_e = ['e\\u1d62\\u209c\\u208B\\u2081']\n",
    "lm.print_table(\n",
    "    (label_ye, label_e), corr_result, \n",
    "    title='Serial Correlation', floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a table that looks like this:\n",
    "\n",
    "Serial Correlation <br>\n",
    "Dependent variable: OLS residual, eᵢₜ\n",
    "\n",
    "|       |    Beta |     Se |   t-values |\n",
    "|-------|---------|--------|------------|\n",
    "| eᵢₜ₋₁ | -0.3961 | 0.0147 |   -27.0185 |\n",
    "R² = 0.182 <br>\n",
    "σ² = 0.143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for strict exogeneity\n",
    "\n",
    "Add a lead of the union variable, $union_{i,t+1}$ to the equation (1) (note that you will lose data from period $T$ , 1987) and estimate the model with *fixed effects* (i.e., you have to demean $union_{i,t+1}$ along with all the other variables and throw out time constant variables). Is $union_{i,t+1}$ significant? What does this imply for the strict exogeneity assumption?\n",
    "\n",
    "*Hint:* To lead a variable, think along the same lines as in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead union\n",
    "F_T = # Fill in\n",
    "\n",
    "union_lead = lm.perm(F_T, x[:, 3].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last observed year for every individual\n",
    "I_T = # Fill in\n",
    "\n",
    "x_exo = lm.perm(I_T, x)\n",
    "y_exo = lm.perm(I_T, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add union_lead to x_exo\n",
    "x_exo = np.hstack((x_exo, union_lead))\n",
    "\n",
    "# Within transform the data\n",
    "Q_T = # Fill in \n",
    "yw_exo = # Fill in \n",
    "xw_exo = # Fill in \n",
    "\n",
    "# Select variables\n",
    "xw_exo = np.hstack((xw_exo[:, 1:5], xw_exo[:, -1].reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate model\n",
    "exo_test = # Fill in\n",
    "\n",
    "# Print results\n",
    "label_exo = label_x_fe + ['Union lead']\n",
    "lm.print_table((label_y, label_exo), exo_test, title='Exogeneity test', floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table should look something like this:\n",
    "Exogeneity test <br>\n",
    "Dependent variable: Log wage\n",
    "\n",
    "|                |    Beta |     Se |   t-values |\n",
    "|----------------|---------|--------|------------|\n",
    "| Experience     |  0.1213 | 0.0100 |    12.1001 |\n",
    "| Experience sqr | -0.0050 | 0.0008 |    -6.3579 |\n",
    "| Married        |  0.0436 | 0.0209 |     2.0898 |\n",
    "| Union          |  0.0757 | 0.0218 |     3.4784 |\n",
    "| Union lead     |  0.0515 | 0.0223 |     2.3063 |\n",
    "R² = 0.146<br>\n",
    "σ² = 0.128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series dummies and FE\n",
    "Add interactions on the form $d_{81}\\cdot educ, d_{82}\\cdot educ, ..., d_{87}\\cdot educ$ and estimate the model with fixed effect. Has the return to education increased over time?\n",
    "\n",
    "*Hint:* Remember that $educ_{i}$ doesn't vary over\n",
    "time! Therefore we didn't use $educ$ in levels in the FE estimation.\n",
    "However, if we suppose that the structural equation (4) contains a term $\\sum_{s=2}^{T}\\delta_{s}d_{s}educ_{i}$, it will be perfectly fine to within-transform these interactions since they vary over time (although in a highly structured manner - they equal\n",
    "zero in all time periods but one, and then $educ$). Note that one\n",
    "period is dropped for the within-transformation to work whereas the\n",
    "levels term, $\\beta_{5}educ_{i}$, is dropped to avoid producing a\n",
    "constant row.\n",
    "\n",
    "*Programming hint:* You want to append the dataset with a dummy matrix, that would look something like this:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "14 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 14 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 14 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "9 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 9 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 9 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This example shows our two first persons, that have 14 and 9 years of education respectively.Why is the first row for each person only zeros?\n",
    "\n",
    "The matrix is constructed for you. Note how it can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dummy block has a 0 row, as we need to exclude one\n",
    "# year in order to not end up in the dummy trap.\n",
    "dummy_block = np.eye(T, k=-1)[:, :-1]\n",
    "\n",
    "# Expand thid dummy block to all persons\n",
    "dummy_matrix = np.tile(dummy_block, (N, 1))\n",
    "\n",
    "# We now create a n*t-1 matrix, with the person's education \n",
    "expanded_educ = np.transpose([x[:, 5]] * (T-1))\n",
    "\n",
    "# We can now multiply the year dummy with a person's education\n",
    "educ_dummies = dummy_matrix*expanded_educ\n",
    "\n",
    "# We can now demean the variables\n",
    "Q_T = demeaning_matrix(T)\n",
    "educ_demean = lm.perm(Q_T, educ_dummies)\n",
    "x_demean_dummies = np.hstack([x_demean, educ_demean])\n",
    "\n",
    "# Add the year dummies to the label\n",
    "label_x_interactions = label_x_fe + ['E81', 'E82', 'E83', 'E84', 'E85', 'E86', 'E87']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate model\n",
    "int_result = # Fill in\n",
    "\n",
    "# Print results\n",
    "lm.print_table((label_y, label_x_interactions), int_result, title='FE with year interactions', floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a table that looks like this:\n",
    "\n",
    "FE with year interactions <br>\n",
    "Dependent variable: Log wage\n",
    "\n",
    "|                |    Beta |     Se |   t-values |\n",
    "|----------------|---------|--------|------------|\n",
    "| Experience     |  0.1705 | 0.0273 |     6.2462 |\n",
    "| Experience sqr | -0.0060 | 0.0009 |    -6.9581 |\n",
    "| Married        |  0.0475 | 0.0183 |     2.5925 |\n",
    "| Union          |  0.0794 | 0.0193 |     4.1138 |\n",
    "| E81            | -0.0010 | 0.0026 |    -0.4009 |\n",
    "| E82            | -0.0062 | 0.0041 |    -1.5224 |\n",
    "| E83            | -0.0114 | 0.0057 |    -2.0006 |\n",
    "| E84            | -0.0136 | 0.0072 |    -1.8787 |\n",
    "| E85            | -0.0162 | 0.0087 |    -1.8578 |\n",
    "| E86            | -0.0170 | 0.0101 |    -1.6804 |\n",
    "| E87            | -0.0167 | 0.0115 |    -1.4619 |\n",
    "R² = 0.181 <br>\n",
    "σ² = 0.123"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
