{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 2\n",
    "Before we start working on some exercises we will briefly introduce two concepts in Python. First, importing and exporting data. Second, using functions. If you are already familiar\n",
    "with these features, you can skip the next two sections and jump directly to the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from tabulate import tabulate\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import chi2\n",
    "import scipy.stats as st\n",
    "\n",
    "#Supress Future Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Import this weeks LinearModels .py file\n",
    "import w2_LinearModels_post as lm\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "### Import data\n",
    "\n",
    "The exercise takes up the union membership example from before. The data set WAGEPAN.TXT contains information about 545 men who worked every year from 1980 to 1987 in the US. The variables of interest are\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log\\left(wage_{it}\\right) & =\\beta_{0}+\\beta_{1}\\textit{exper}_{it}+\\beta_{2}\\textit{exper}_{it}^{2}+\\beta_{3}\\textit{union}_{it}+\\beta_{4}\\textit{married}_{i} +\\beta_{5}\\textit{educ}_{i}+\\beta_{6}\\textit{hisp}_{i}+\\beta_{7}\\textit{black}_{i}+c_{i}+u_{it} \\tag{1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Note that *educ*, *hisp*, and *black* are time-invariant variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has 10 columns. Named from 0 to 9. Here is a variable describtion:\n",
    "- Column 0: ID\n",
    "- Column 1: Year\n",
    "- Column 2: Black\n",
    "- Column 3: Experience\n",
    "- Column 4: Hispanic\n",
    "- Column 5: Married\n",
    "- Column 6: Education\n",
    "- Column 7: Union\n",
    "- Column 8: ln wage\n",
    "- Column 9: Experience sqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by loading the data. Some of this has been done for you already. Since we are working with panels, we need to know how many persons there are and how many time periods we observe them. Since we operate using a balanced panel, this makes our life a little easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the data into numpy. \n",
    "# Data should load the firms.csv file provided for the production function exercises.\n",
    "data = np.loadtxt('firms.csv', delimiter=',', skiprows=1)\n",
    "id_array = data[:, 0].astype(int)\n",
    "\n",
    "# Count how many firms we have and how many years per firm.\n",
    "unique_id = np.unique(id_array, return_counts=True)\n",
    "N = unique_id[0].size\n",
    "T = int(unique_id[1].mean())\n",
    "year = data[:, 1].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the rest of the data into arrays.\n",
    "# Dependent variable: log deflated sales (ldsa).\n",
    "y = data[:, 4].reshape(-1, 1)\n",
    "\n",
    "# Regressors: constant, log labour, log capital.\n",
    "x = np.column_stack([\n",
    "    np.ones(N * T),\n",
    "    data[:, 3],  # log labour\n",
    "    data[:, 2]   # log capital\n",
    "])\n",
    "\n",
    "label_y = 'Log deflated sales'\n",
    "label_x = ['Constant', 'Log labour', 'Log capital']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooled OLS (POLS) Estimator\n",
    "- **Estimate (1) by pooled OLS,** thus considering for the moment the unobserved components of (q) as one (composite) error term $v_{it}=c_{i}+u_{it}$. \n",
    "- Fill in the remaining parts of the function est_ols() in the accompanying python file (LinearModelsWeek2_ante.py) to estimate the model.\n",
    "- What assumptions are made about $E\\left[c_{i}\\mathbf{x}_{it}\\right]$ and $E\\left[u_{it}\\mathbf{x}_{it}\\right]$ when justifying this estimation approach? (Hint: See Wooldridge p. 283)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant        :  0.0000\n",
      "Log labour      :  0.6748\n",
      "Log capital     :  0.3100\n"
     ]
    }
   ],
   "source": [
    "# Estimate coefficients\n",
    "b_hat = lm.est_ols(y,x)\n",
    "\n",
    "# Print the results\n",
    "for label, b_k in zip(label_x, b_hat):\n",
    "    print(f'{label:16}: {b_k[0]:7.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the standard errors of the coefficients. This is very similar to previous week's exercise. (Hint: See Wooldridge p. 59-60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant        :  0.0000    (0.0050)\n",
      "Log labour      :  0.6748    (0.0102)\n",
      "Log capital     :  0.3100    (0.0091)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the residuals\n",
    "resid = y - x @ b_hat\n",
    "\n",
    "# Calculate estimate of variance of residuals\n",
    "SSR = resid.T @ resid\n",
    "K = x.shape[1]\n",
    "sigma = SSR / (N*T - K)\n",
    "\n",
    "# Calculate the variance-covariance matrix\n",
    "cov = sigma * la.inv(x.T @ x)\n",
    "\n",
    "# Calculate the standard errors \n",
    "# Make sure to output the result in a vector\n",
    "se = np.sqrt(np.diag(cov)).reshape(-1,1)\n",
    "\n",
    "#Print results\n",
    "for label, b_k, se_k in zip(label_x, b_hat, se):\n",
    "    print(f'{label:16}: {b_k[0]:7.4f}    ({se_k[0]:6.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the functions estimate() and variance() in the accompanying python file. You can reuse most of the code above.\n",
    "\n",
    "Using the function, print_table(), you should reproduce the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled OLS\n",
      "Dependent variable: Log deflated sales\n",
      "\n",
      "               Beta      Se    t-values\n",
      "-----------  ------  ------  ----------\n",
      "Constant     0.0000  0.0161      0.0000\n",
      "Log labour   0.6748  0.0366     18.4526\n",
      "Log capital  0.3100  0.0324      9.5810\n",
      "R² = 0.914\n",
      "σ² = 0.131\n"
     ]
    }
   ],
   "source": [
    "# Estimate model using OLS\n",
    "ols_result = lm.estimate(y,x, N=N, T=T, robust_se=True)\n",
    "\n",
    "# Print table\n",
    "lm.print_table((label_y, label_x), ols_result, title=\"Pooled OLS\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CRS restriction helpers ---\n",
    "def _crs_wald(results, skip):\n",
    "    b = results['b_hat'][skip:, :]\n",
    "    cov = results['cov'][skip:, skip:]\n",
    "    R = np.array([[1.0, 1.0]])\n",
    "    q = np.array([[1.0]])\n",
    "    diff = R @ b - q\n",
    "    var_Rb = R @ cov @ R.T\n",
    "    W = (diff.T @ la.inv(var_Rb) @ diff).item()\n",
    "    crit = chi2.ppf(0.95, 1)\n",
    "    p_val = 1 - st.chi2.cdf(W, 1)\n",
    "    return W, crit, p_val\n",
    "\n",
    "def crs_test_fe(results):\n",
    "    return _crs_wald(results, 0)\n",
    "\n",
    "def crs_test_fd(results):\n",
    "    return _crs_wald(results, 0)\n",
    "\n",
    "def crs_test_re(results):\n",
    "    return _crs_wald(results, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed Effects (FE) Estimator\n",
    "In the next step, we will estimate the model using fixed effects. This is done by first performing the fixed effects (within-groups) transformation on the data and then using pooled OLS on the transformed data.\n",
    "We will break this down into multiple steps.\n",
    "\n",
    "### Using numpy\n",
    "Create a transformation matrix with dimensions $T \\times T$ that can be used to transform the data. Note that the matrix will be premultiplied on the data for each individual, so the dimensions will match in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformation matrix\n",
    "def demeaning_matrix(T):\n",
    "    Q_T = np.eye(T) - np.tile(1/T, (T, T))\n",
    "    return Q_T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the supplied perm() function to apply the transformation to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the demeaning matrix\n",
    "Q_T = demeaning_matrix(T)\n",
    "\n",
    "# Transform the data\n",
    "y_demean = lm.perm(Q_T, y)\n",
    "x_demean = lm.perm(Q_T, x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the rank and eigenvalues of the within transformed $\\mathbf{X}$ matrix? Why?\n",
    "\n",
    "What happens to *educ, hisp, and black* and the constant when the data are within transformed? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to check rank of demeaned matrix, and return its eigenvalues.\n",
    "def check_rank(x):\n",
    "    print(f'Rank of demeaned x: {la.matrix_rank(x)}')\n",
    "    lambdas, V = la.eig(x.T@x)\n",
    "    np.set_printoptions(suppress=True)  # This is just to print nicely.\n",
    "    print(f'Eigenvalues of within-transformed x: {lambdas.round(decimals=0)}')\n",
    "    print(V)\n",
    "    # Use eigen vectors to identify which variables are dropped.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust `x_demean` such that the model can be estimated using the FE estimator. Adjust the labels to match with `x_demean`.\n",
    "\n",
    "Estimate the model using the estimate() function, and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose variables to include in fixed effects model\n",
    "x_demean = x_demean[:, 1:]\n",
    "label_x_fe = label_x[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FE regression\n",
      "Dependent variable: Log deflated sales\n",
      "\n",
      "               Beta      Se    t-values\n",
      "-----------  ------  ------  ----------\n",
      "Log labour   0.6942  0.0417     16.6674\n",
      "Log capital  0.1546  0.0299      5.1630\n",
      "R² = 0.477\n",
      "σ² = 0.018\n"
     ]
    }
   ],
   "source": [
    "# Estimate FE OLS using the demeaned variables.\n",
    "fe_result = lm.estimate(y_demean, x_demean, transform='fe', N=N, T=T, robust_se=True)\n",
    "\n",
    "# Print results\n",
    "lm.print_table((label_y, label_x_fe), fe_result, title='FE regression', floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f706562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Between estimator feeding the RE calculations\n",
    "P_T = np.ones((1, T)) / T\n",
    "y_mean = lm.perm(P_T, y)\n",
    "x_mean = lm.perm(P_T, x)\n",
    "be_result = lm.estimate(y_mean, x_mean, transform='be', N=N, T=T, robust_se=True)\n",
    "lm.print_table((label_y, label_x), be_result, title='Between Estimator', floatfmt='.4f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c116fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quasi-demeaning parameter for RE\n",
    "sigma2_u = float(fe_result['sigma'])\n",
    "sigma2_w = float(be_result['sigma'])\n",
    "sigma2_c = max(sigma2_w - sigma2_u / T, 0.0)\n",
    "_lambda = 1 - np.sqrt(sigma2_u / (sigma2_u + T * sigma2_c))\n",
    "print(f'Lambda is approximately equal to {_lambda:.4f}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3445886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random effects transformation and estimation\n",
    "P_T_full = np.ones((T, T)) / T\n",
    "C_T = np.eye(T) - _lambda * P_T_full\n",
    "y_re = lm.perm(C_T, y)\n",
    "x_re = lm.perm(C_T, x)\n",
    "re_result = lm.estimate(y_re, x_re, transform='re', N=N, T=T, robust_se=True)\n",
    "lm.print_table((label_y, label_x), re_result, title='Random Effects', floatfmt='.4f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First-difference (FD) Estimator\n",
    "Construct $\\mathbf{D}$ and use the procedure `perm` $(\\mathbf{D},\\mathbf{x})$ to compute first differences of the elements of $\\mathbf{y}$ and $\\mathbf{x}$. $\\mathbf{D}$ should be a $(T-1) \\times T$ matrix. Why?\n",
    "\n",
    "What happens to *educ, hisp* and *black* and the constant when the data are transformed into first differences? What is the rank of the first differenced $\\mathbf{x}$-matrix? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First differening matrix for T=12 \n",
      " [[-1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. -1.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. -1.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0. -1.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. -1.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0. -1.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0. -1.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# Create transformation matrix\n",
    "def fd_matrix(T):\n",
    "    D_T = np.eye(T) - np.eye(T, k=-1)\n",
    "    D_T = D_T[1:]\n",
    "    return D_T\n",
    "\n",
    "# Print the matrix\n",
    "D_T = fd_matrix(T)\n",
    "print(f'First differening matrix for T={T} \\n', D_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         0.000907  -0.0733878]\n",
      " [ 0.        -0.023856  -0.0455976]\n",
      " [ 0.        -0.052741  -0.0365186]\n",
      " ...\n",
      " [ 0.         0.102943   0.172166 ]\n",
      " [ 0.         0.048671   0.182393 ]\n",
      " [ 0.         0.056783   0.014258 ]]\n"
     ]
    }
   ],
   "source": [
    "# Transform the data.\n",
    "y_diff = lm.perm(D_T, y)\n",
    "x_diff = lm.perm(D_T, x)\n",
    "\n",
    "# Print x_diff\n",
    "print(x_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of demeaned x: 2\n",
      "Eigenvalues of within-transformed x: [35. 47.  0.]\n",
      "[[ 0.          0.          1.        ]\n",
      " [ 0.6043423  -0.79672478  0.        ]\n",
      " [-0.79672478 -0.6043423   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Check rank condition.\n",
    "check_rank(x_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust `x_diff` such that the model can be estimated using the FD estimator. Adjust the labels to match with `x_diff`.\n",
    "\n",
    "Estimate the model using the estimate() function, and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose variables to include in first-difference model\n",
    "x_diff = x_diff[:, 1:]\n",
    "label_x_fd = label_x[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRS Wald test (FE): 19.4029\n",
      "Critical value (5%): 3.8415\n",
      "p-value: 0.0000\n",
      "CRS Wald test (FD): 150.0280\n",
      "Critical value (5%): 3.8415\n",
      "p-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# CRS Wald tests for FE, FD, and RE\n",
    "\n",
    "# Ensure FD result is evaluated\n",
    "fd_result = lm.estimate(y_diff, x_diff, transform='fd', N=N, T=T-1, robust_se=True)\n",
    "\n",
    "W_fe, crit_fe, pval_fe = crs_test_fe(fe_result)\n",
    "print(f'CRS Wald test (FE): {W_fe:.4f}')\n",
    "print(f'Critical value (5%): {crit_fe:.4f}')\n",
    "print(f'p-value: {pval_fe:.4f}')\n",
    "\n",
    "W_fd, crit_fd, pval_fd = crs_test_fd(fd_result)\n",
    "print(f'CRS Wald test (FD): {W_fd:.4f}')\n",
    "print(f'Critical value (5%): {crit_fd:.4f}')\n",
    "print(f'p-value: {pval_fd:.4f}')\n",
    "\n",
    "W_re, crit_re, pval_re = crs_test_re(re_result)\n",
    "print(f'CRS Wald test (RE): {W_re:.4f}')\n",
    "print(f'Critical value (5%): {crit_re:.4f}')\n",
    "print(f'p-value: {pval_re:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD regression\n",
      "Dependent variable: Log deflated sales\n",
      "\n",
      "               Beta      Se    t-values\n",
      "-----------  ------  ------  ----------\n",
      "Log labour   0.5487  0.0292     18.8191\n",
      "Log capital  0.0630  0.0232      2.7097\n",
      "R² = 0.165\n",
      "σ² = 0.014\n"
     ]
    }
   ],
   "source": [
    "# Estimate FE OLS using the demeaned variables.\n",
    "fd_result = lm.estimate(y_diff, x_diff, transform='fd', N=N, T=T-1, robust_se=True)\n",
    "\n",
    "# Print results\n",
    "lm.print_table((label_y, label_x_fd), fd_result, title='FD regression', floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a table that looks like this:\n",
    "\n",
    "FD regression <br>\n",
    "Dependent variable: Log wage\n",
    "\n",
    "|                |    Beta |     Se |   t-values |\n",
    "|----------------|---------|--------|------------|\n",
    "| Experience     |  0.1158 | 0.0196 |     5.9096 |\n",
    "| Experience sqr | -0.0039 | 0.0014 |    -2.8005 |\n",
    "| Union          |  0.0428 | 0.0197 |     2.1767 |\n",
    "| Married        |  0.0381 | 0.0229 |     1.6633 |\n",
    "R² = 0.004 <br>\n",
    "σ² = 0.196\n",
    "\n",
    "**NB:** Did you use the right standard errors? Did you use the right number of time periods in the estimate() function?\n",
    "\n",
    "How big is the union premium according to the estimate from this model? Compare the FD estimate with the estimate that you calculated from the FE regression. Is there a difference? If yes, what (if anything) can we conclude based on this finding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "### Test for serial correlation in the errors using an auxilliary AR(1) model\n",
    "Tests assumption FD.3, where the errors $e_{it} = \\Delta u_{it}$ should be serially uncorrelated.\n",
    "\n",
    "We can easily test this assumption given the OLS residuals from the FD version of equation (1). Run the regression (note that you will lose data for\n",
    "the first *two* periods)\n",
    "\\begin{equation}\n",
    "\\hat{e}_{it}=\\rho\\hat{e}_{it-1}+error_{it},\\quad t=\\color{red}{3},\\dotsc,T,\\quad i=1,\\dotsc,N\\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "Do you find any evidence of serial correlation? Does FD.3 seem appropriate? And why don't we include an intercept in this auxilliary equation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* Under FE.3, the idiosyncratic errors $u_{it}$\n",
    "are uncorrelated. However, FE.3 implies that the $e_{it}$'s are autocorrelated. In fact, of the $u_{it}$'s are serially uncorrelated to begin with, corr $\\left(e_{it},e_{it-1}\\right)=-0.5$. (Check!) This test is of course only valid if the explanatory variables are strictly exogenous!\n",
    "\n",
    "*Hint:* You can use the `perm` function to lag\n",
    "the error term variable. Consider the following; \n",
    "\n",
    "$$\n",
    "{\\begin{bmatrix}\n",
    "1 & 0 & 0 & \\cdots & 0 & 0\\\\\n",
    "0 & 1 & 0 & \\cdots & 0 & 0\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots\\\\\n",
    "0 & 0 & 0 & \\cdots & 1 & 0\n",
    "\\end{bmatrix}}_{T-1\\times T}\\times{\\begin{bmatrix}y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "\\vdots\\\\\n",
    "y_{T}\n",
    "\\end{bmatrix}}_{T \\times 1}={\\begin{bmatrix}y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "\\vdots\\\\\n",
    "y_{T - 1}\n",
    "\\end{bmatrix}}_{T - 1\\times 1}\n",
    "$$\n",
    "\n",
    "*Hint:* You can use the `perm` function to remove the first time-period in the residual. Consider the following; \n",
    "\n",
    "$$\n",
    "{\\begin{bmatrix}\n",
    "0 & 1 & 0 & \\cdots & 0 & 0\\\\\n",
    "0 & 0 & 1 & \\cdots & 0 & 0\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots\\\\\n",
    "0 & 0 & 0 & \\cdots & 0 & 1\n",
    "\\end{bmatrix}}_{T-1\\times T}\\times{\\begin{bmatrix}y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "\\vdots\\\\\n",
    "y_{T}\n",
    "\\end{bmatrix}}_{T \\times 1}={\\begin{bmatrix}y_{2}\\\\\n",
    "y_{3}\\\\\n",
    "\\vdots\\\\\n",
    "y_{T}\n",
    "\\end{bmatrix}}_{T - 1\\times 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make function to calculate the serial correlation\n",
    "def serial_corr(y, x, T):\n",
    "    # Calculate the residuals\n",
    "    b_hat = lm.est_ols(y, x)\n",
    "    e = y - x@b_hat\n",
    "    \n",
    "    # Create a lag transformation matrix\n",
    "    L_T = np.eye(T, k=-1)\n",
    "    L_T = L_T[1:]\n",
    "\n",
    "    # Lag residuals\n",
    "    e_l = lm.perm(L_T, e)\n",
    "\n",
    "    # Create a transformation matrix that removes the first observation of each individual\n",
    "    I_T = np.eye(T, k=0)\n",
    "    I_T = I_T[1:]\n",
    "    \n",
    "    # Remove first observation of each individual\n",
    "    e = lm.perm(I_T, e)\n",
    "    \n",
    "    # Calculate the serial correlation\n",
    "    return lm.estimate(e, e_l,N=N,T=T-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial Correlation\n",
      "Dependent variable: OLS residual, eᵢₜ\n",
      "\n",
      "          Beta      Se    t-values\n",
      "-----  -------  ------  ----------\n",
      "eᵢₜ₋₁  -0.1987  0.0148    -13.4493\n",
      "R² = 0.039\n",
      "σ² = 0.014\n"
     ]
    }
   ],
   "source": [
    "# Estimate serial correlation\n",
    "corr_result = serial_corr(y_diff, x_diff, T-1)\n",
    "\n",
    "# Print results\n",
    "label_ye = 'OLS residual, e\\u1d62\\u209c'\n",
    "label_e = ['e\\u1d62\\u209c\\u208B\\u2081']\n",
    "lm.print_table(\n",
    "    (label_ye, label_e), corr_result, \n",
    "    title='Serial Correlation', floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a table that looks like this:\n",
    "\n",
    "Serial Correlation <br>\n",
    "Dependent variable: OLS residual, eᵢₜ\n",
    "\n",
    "|       |    Beta |     Se |   t-values |\n",
    "|-------|---------|--------|------------|\n",
    "| eᵢₜ₋₁ | -0.3961 | 0.0147 |   -27.0185 |\n",
    "R² = 0.182 <br>\n",
    "σ² = 0.143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for strict exogeneity\n",
    "\n",
    "Add a lead of the union variable, $union_{i,t+1}$ to the equation (1) (note that you will lose data from period $T$ , 1987) and estimate the model with *fixed effects* (i.e., you have to demean $union_{i,t+1}$ along with all the other variables and throw out time constant variables). Is $union_{i,t+1}$ significant? What does this imply for the strict exogeneity assumption?\n",
    "\n",
    "*Hint:* To lead a variable, think along the same lines as in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead log labour\n",
    "F_T = np.eye(T, k=1)[:-1]\n",
    "lemp_lead = lm.perm(F_T, x[:, 1].reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last observed year for every individual\n",
    "I_T = np.eye(T, k=0)\n",
    "I_T = I_T[:-1]\n",
    "\n",
    "x_exo = lm.perm(I_T, x)\n",
    "y_exo = lm.perm(I_T, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add lemp_lead to x_exo\n",
    "x_exo = np.hstack((x_exo, lemp_lead))\n",
    "\n",
    "# Within transform the data\n",
    "Q_T = demeaning_matrix(T - 1)\n",
    "yw_exo = lm.perm(Q_T, y_exo)\n",
    "xw_exo = lm.perm(Q_T, x_exo)\n",
    "\n",
    "# Drop the demeaned constant and keep labour, capital, lead labour\n",
    "xw_exo = xw_exo[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exogeneity test\n",
      "Dependent variable: Log deflated sales\n",
      "\n",
      "                   Beta      Se    t-values\n",
      "---------------  ------  ------  ----------\n",
      "Log labour       0.5681  0.0397     14.3113\n",
      "Log capital      0.1495  0.0291      5.1287\n",
      "Lead log labour  0.1532  0.0281      5.4442\n",
      "R² = 0.473\n",
      "σ² = 0.016\n"
     ]
    }
   ],
   "source": [
    "# Estimate model\n",
    "exo_test = lm.estimate(yw_exo, xw_exo, N=N, T=T - 1, transform='fe', robust_se=True)\n",
    "\n",
    "# Print results\n",
    "label_exo = label_x_fe + ['Lead log labour']\n",
    "lm.print_table((label_y, label_exo), exo_test, title='Exogeneity test', floatfmt='.4f')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
