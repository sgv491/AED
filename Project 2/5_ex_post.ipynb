{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: High-Dimensional Methods and Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this week's problem set is to get familiar with inference based on high-dimensional methods.  Our focus is again on methods based on the Lasso, and we again use the <tt>housing.csv</tt> dataset. (See the previous problem set for data details.) Note how our focus has here changed from prediction (of house prices) to inference (drivers of house prices).\n",
    "\n",
    "We first read the data into Python and remove missings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'housing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolynomialFeatures\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Read data\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m housing \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhousing.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m housing\u001b[38;5;241m=\u001b[39mhousing\u001b[38;5;241m.\u001b[39mdropna() \u001b[38;5;66;03m# dropping observations missing a bedroom count \u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of rows and columns are \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and also called shape of the matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(housing\u001b[38;5;241m.\u001b[39mshape))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'housing.csv'"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Read data\n",
    "housing = pd.read_csv(\"housing.csv\")\n",
    "housing=housing.dropna() # dropping observations missing a bedroom count \n",
    "print(\"The number of rows and columns are {} and also called shape of the matrix\".format(housing.shape)) # data dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns names are \\n {}\".format(housing.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing.head()) # first observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing.tail()) # last observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing.dtypes) # data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We model house prices (<tt>median_house_value</tt>) using a linear (in the parameters) model of the basic regressors (minus the categorical variable <tt>ocean_proximity</tt>). \n",
    "\n",
    "$$\n",
    "\\underbrace{\\mathtt{median\\,house\\,value}}_{=Y}= \\alpha\\times\\underbrace{\\mathtt{median\\,income}}_{=D} + Z'\\gamma + \\varepsilon,\\quad\\mathrm{E}[\\varepsilon|D,Z]=0.\n",
    "$$\n",
    "\n",
    "Note that Z should contains a constant, but the implementation of Lasso in sklearn adds this automatically.\n",
    "\n",
    "We here focus on constructing a confidence interval for the coefficient of <tt>median_income</tt> after having used the Lasso. In doing so we treat both <tt>median_income</tt> and the remaining ($p=7$) contrOLS as exogenous. Moreover, we augment the above model with another linear model\n",
    "\n",
    "$$\n",
    "\\mathtt{median\\,income}=Z'\\psi + \\nu,\\quad\\mathrm{E[\\nu|Z]=0},\n",
    "$$\n",
    "\n",
    "now for <tt>median_income</tt>.\n",
    "\n",
    "(One would be hard pressed to claim that median income *causes* house price movements. This is only an exercise in the mechanics.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## Part 1: Prepare data\n",
    "Use the eight basic regressors ($Z_1,\\dotsc,Z_p$) and add all control quadratics ($Z_1^2,\\dotsc,Z_p^2$), cubics ($Z_1^3,\\dotsc,Z_p^3$), first-order interactions ($Z_1Z_2,Z_1Z_3,\\dotsc,Z_{p-1}Z_{p}$), and second-order interactions ($Z_1Z_1Z_2,Z_1Z_1Z_3,\\dotsc,Z_{p}Z_{p}Z_{p-1}$). \n",
    "\n",
    "Hints: Use <tt>sklearn.preprocessing.PolynomialFeatures</tt> for simple transformation. Your optimizer may not converge. Consider increasing the maximum number of iterations using the Lasso option <tt>max_iter=</tt>[your number]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.1\n",
    "Setup data and add all control quadratics, cubics, first-order interactions, and second-order interactions. Don't include a constant - this is done automatically by the Lasso implementation in python. How many regressors do you have now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data\n",
    "y = housing.median_house_value\n",
    "d = housing.median_income\n",
    "Z_basic = housing.drop([\"median_house_value\",\"median_income\",\"ocean_proximity\"],axis=1)\n",
    "\n",
    "# Add polynomial features\n",
    "# Hint: remember, you don't want the constant\n",
    "Z = PolynomialFeatures(3, include_bias=False).fit_transform(Z_basic)\n",
    "\n",
    "# Display number of regressors\n",
    "print(\"The number of regressors in Z is {}\".format(Z.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get: The number of regressors in Z is 119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct X \n",
    "X = np.column_stack((d,Z))\n",
    "\n",
    "# Find N\n",
    "N = X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2\n",
    "Standardize variables before running the Lasso.\n",
    "\n",
    "*Note:* Make sure make a degrees of freedom correction when computing the standard errors. Pandas does this automatically, but if you use numpy, you should set the argument ddof=1 in the function np.std()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for standardizing\n",
    "def standardize(X):\n",
    "\n",
    "    X_stan = (X - np.mean(X, axis=0))/np.std(X, axis=0, ddof=1)\n",
    "    return X_stan\n",
    "\n",
    "# Standardize data\n",
    "X_stan = standardize(X)\n",
    "Z_stan = standardize(Z)\n",
    "d_stan = standardize(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Students get slightly different answers with each different version of Python. Your results for Exercise 3 should be correct to 3 significant figures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1\n",
    "Estimate $\\alpha$ using Ordinary Least Squares (OLS). Remember to add a constant to the regressors for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant to X\n",
    "xx = np.column_stack((np.ones(N),X))\n",
    "\n",
    "# Reshape y\n",
    "yy = np.array(y).reshape(-1,1)\n",
    "\n",
    "# Calculate OLS estimate\n",
    "coefs_OLS = la.inv(xx.T@xx)@xx.T@yy\n",
    "alpha_OLS = coefs_OLS[1][0]\n",
    "\n",
    "# Calculate residuals\n",
    "res_OLS = yy - xx@coefs_OLS\n",
    "\n",
    "# Display alpha\n",
    "print(\"alpha_OLS = \",alpha_OLS.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hint: We are doing OLS not Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get: alpha_OLS =  37143.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the variance of the OLS estimator and calculate the standard deviation of $\\hat{\\alpha}$. For this exercise we will assume homoscedasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate variance\n",
    "SSR = res_OLS.T@res_OLS\n",
    "sigma2_OLS = SSR/(N-xx.shape[1])\n",
    "var = sigma2_OLS*la.inv(xx.T@xx)\n",
    "\n",
    "# Calculate standard errors\n",
    "se = np.sqrt(np.diagonal(var)).reshape(-1,1)\n",
    "\n",
    "# Get standard error of alpha\n",
    "se_OLS = se[1][0]\n",
    "\n",
    "# Display standard error\n",
    "print(\"se_OLS = \",se_OLS.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get:  se_OLS =  394.41"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the 95% confidence interval for $\\hat{\\alpha}$.\n",
    "\n",
    "*Hint:* Use scipy.stats.norm.ppf to find quantiles of the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the quantile of the standard normal distribution that corresponds to the 95% confidence interval of a two-sided test\n",
    "q = norm.ppf(1-0.025)\n",
    "\n",
    "# Calculate confidence interval\n",
    "CI_low_OLS  = alpha_OLS-q*se_OLS\n",
    "CI_high_OLS = alpha_OLS+q*se_OLS\n",
    "\n",
    "# Display confidence interval\n",
    "CI_OLS =  (((alpha_OLS-q*se_OLS).round(2),(alpha_OLS+q*se_OLS).round(2)))\n",
    "print(\"CI_OLS = \",(CI_low_OLS.round(2),CI_high_OLS.round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get:  CI_OLS =  (36370.76, 37916.84)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Post-Single Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.1\n",
    "Estimate $\\alpha$ using Post-Single Lasso (PSL)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 0: Calculate BRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function that calculates BRT. Hint: You implemented a version of this last week\n",
    "def BRT(X_tilde,y):\n",
    "    (N,p) = X_tilde.shape\n",
    "    sigma = np.std(y, ddof=1)\n",
    "    c=1.1\n",
    "    alpha=0.05\n",
    "\n",
    "    penalty_BRT= (sigma*c)/np.sqrt(N)*norm.ppf(1-alpha/(2*p))\n",
    "\n",
    "    return penalty_BRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate BRT\n",
    "penalty_BRTyx = BRT(X_stan, y)\n",
    "print(\"lambda_BRT =\",penalty_BRTyx.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get:  lambda_BRT = 3135.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Lasso Y using D and Z. Collect variables in Z with non-zero coefficients in a set called Z_J.\n",
    "\n",
    "*Hint:* Set max_iter=10_000 to make the Lasso converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso \n",
    "fit_BRTyx = Lasso(penalty_BRTyx, max_iter=10000).fit(X_stan,y)\n",
    "coefs=fit_BRTyx.coef_\n",
    "\n",
    "# Save variables where coefficients are not zero\n",
    "Z_J = Z[:,coefs[1:]!=0] # Note: We use Z and not Z_stan\n",
    "\n",
    "# Display number of variables in Z_J\n",
    "print(\"The number of variables in Z_J is {}\".format(Z_J.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get: The number of variables in Z_J is 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Regress Y using D and Z_J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant to X\n",
    "xx = np.column_stack((np.ones(N),d,Z_J))\n",
    "yy = np.array(y).reshape(-1,1)\n",
    "\n",
    "# Calculate OLS estimate\n",
    "coefs_PSL = la.inv(xx.T@xx)@xx.T@yy\n",
    "alpha_PSL = coefs_PSL[1][0]\n",
    "\n",
    "# Calculate residuals\n",
    "res_PSL = yy - xx@coefs_PSL\n",
    "\n",
    "# Display alpha\n",
    "print(\"alpha_PSL = \",alpha_PSL.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get: alpha_PSL =  38147.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the variance of the second step OLS estimator and calculate the standard deviation of $\\tilde{\\alpha}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate variance\n",
    "SSR = res_PSL.T@res_PSL\n",
    "sigma2_PSL = SSR/(N-xx.shape[1])\n",
    "var = sigma2_PSL*la.inv(xx.T@xx)\n",
    "\n",
    "# Calculate standard errors\n",
    "se = np.sqrt(np.diagonal(var)).reshape(-1, 1)\n",
    "se_PSL=se[1][0]\n",
    "\n",
    "# Display standard error\n",
    "print(\"se_PSL = \",se_PSL.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get: se_PSL =  268.92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the 95% confidence interval for $\\tilde{\\alpha}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the z statistic that corresponds to the 95% confidence interval of a two-sided test\n",
    "q = norm.ppf(1-0.025)\n",
    "\n",
    "# Calculate confidence interval\n",
    "CI_low_PSL  = alpha_PSL-q*se_PSL\n",
    "CI_high_PSL = alpha_PSL+q*se_PSL\n",
    "\n",
    "# Display confidence interval\n",
    "CI_PSL =  (((alpha_PSL-q*se_PSL).round(2),(alpha_PSL+q*se_PSL).round(2)))\n",
    "print(\"CI_PSL = \",(CI_low_PSL.round(2),CI_high_PSL.round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get: CI_PSL =  (37620.01, 38674.14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Double Post Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.1\n",
    "Estimate $\\alpha$ using Double Post Lasso (DPL)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 0: Calculate BRT\n",
    "\n",
    "*Note:* In this exercise we will use the penalty suggested by BRT. BRT relies on homoscedasticity which is a strong assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate BRT\n",
    "penalty_BRTyx = BRT(X_stan,y)\n",
    "print(\"lambda_BRT =\",penalty_BRTyx.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get: lambda_BRT = 3135.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Lasso Y using D and Z\n",
    "\n",
    "*Hint:* To calculate the residuals from the LASSO-regression you can use the predict method from the Lasso object. The predict method returns the predicted values from the LASSO regression. You can then calculate the residuals by subtracting the predicted values from the actual values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso \n",
    "fit_BRTyx = Lasso(penalty_BRTyx, max_iter=10000).fit(X_stan, y)\n",
    "coefs=fit_BRTyx.coef_\n",
    "\n",
    "# Calculate residuals\n",
    "resyx = y-fit_BRTyx.predict(X_stan)\n",
    "\n",
    "# Calculate Y - Z@gamma (epsilon + alpha*d)\n",
    "# Hint: You only need the variables given to you in this cell, in addition\n",
    "# to a standardized data set you made previoously.\n",
    "resyxz = resyx + d_stan*coefs[0]\n",
    "\n",
    "# Display first coefficient\n",
    "print(\"First coefficient =\",coefs[0].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get: First coefficient = 74248.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Lasso D using Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate BRT\n",
    "penalty_BRTdz = BRT(Z_stan, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso\n",
    "fit_BRTdz = Lasso(penalty_BRTdz, max_iter=10000).fit(Z_stan, d)\n",
    "coefs=fit_BRTdz.coef_\n",
    "\n",
    "# Calculate residuals\n",
    "resdz=d-fit_BRTdz.predict(Z_stan)\n",
    "\n",
    "# Display first coefficient\n",
    "print(\"First coefficient =\",coefs[0].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get: First coefficient = -0.55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Estimate alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate alpha\n",
    "num = resdz@resyxz\n",
    "denom = resdz@d\n",
    "alpha_PDL = num/denom\n",
    "\n",
    "# Display alpha\n",
    "print(\"alpha_PDL = \",alpha_PDL.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get: alpha_PDL =  40788.63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.2\n",
    "Calculate the implied variance estimate, $\\check{\\sigma}^2$, and calculate the standard deviation of $\\check{\\alpha}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resdz)\n",
    "print(resyxz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variance    \n",
    "num = resdz**2@resyx**2/N\n",
    "denom = (resdz.T@resdz/N)**2\n",
    "sigma2_PDL = num/denom\n",
    "\n",
    "# Display variance\n",
    "print(\"sigma2_PDL = \",sigma2_PDL.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get: sigma2_PDL =  4557181789.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate standard error\n",
    "se_PDL = np.sqrt(sigma2_PDL/N)\n",
    "\n",
    "# Display standard error\n",
    "print(\"se_PDL = \",se_PDL.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get: se_PDL =  472.26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.3\n",
    "Calculate the confidence interval for $\\check{\\alpha}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the quantile of the standard normal distribution that corresponds to the 95% confidence interval of a two-sided test\n",
    "q = norm.ppf(1-0.025)\n",
    "\n",
    "# Calculate confidence interval\n",
    "CI_low_PDL  = alpha_PDL - q * se_PDL\n",
    "CI_high_PDL = alpha_PDL + q * se_PDL\n",
    "\n",
    "# Display confidence interval\n",
    "print(\"CI_PDL = \",(CI_low_PDL.round(2),CI_high_PDL.round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get: CI_PDL =  (39863.01, 41714.24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.4\n",
    "Compare OLS, PSL and PDL. \n",
    "- Which estimator do you believe the most? \n",
    "- Does the dimensionality of the problem affect your answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the results\n",
    "results = {'OLS': [alpha_OLS, se_OLS, CI_low_OLS, CI_high_OLS], \n",
    "           'PSL': [alpha_PSL, se_PSL, CI_low_PSL, CI_high_PSL],\n",
    "           'PDL': [alpha_PDL, se_PDL, CI_low_PDL, CI_high_PDL]}\n",
    "\n",
    "# Create a dataframe from the dictionary\n",
    "df_results = pd.DataFrame.from_dict(results, orient='index', columns=['Estimate of alpha', 'Standard error', 'Low bound of CI', 'High bound of CI'])\n",
    "\n",
    "# Format the dataframe to two digits after the comma\n",
    "df_results = df_results.round(2)\n",
    "\n",
    "# Display the dataframe\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get:\n",
    "|      | Estimate of alpha | Standard error | Low bound of CI | High bound of CI |\n",
    "|-----:|------------------:|---------------:|----------------:|-----------------:|\n",
    "|  OLS |          37143.80 |         394.41 |        36370.76 |         37915.84 |\n",
    "|  PSL |          38147.07 |         268.92 |        37620.01 |         38674.14 |\n",
    "|  PDL |          40788.63 |         472.26 |        39863.01 |         41714.24 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Post Partialling Out Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to Post Double Lasso is Post Partialling Out Lasso (PPOL). PPOL is based on another orthogonalized moment condition, which is asymptotically first order equivalent to the one used in Post Double Lasso,\n",
    "\n",
    "$$\n",
    "E[(D - Z'\\psi_0) ([Y - Z'\\delta_0] - \\alpha_0[D - Z' \\psi_0])] = 0 \n",
    "$$\n",
    "\n",
    "The PPOL estimator of $\\alpha_0$ can be found by applying the following 3 steps:\n",
    "1. Lasso Y using Z to get residuals $\\hat{\\zeta} = Y - Z' \\hat{\\delta}$\n",
    "2. Lasso D using Z to get residuals $\\hat{\\nu} = D - Z' \\hat{\\psi}$\n",
    "3. OLS of $\\hat{\\zeta}$ on $\\hat{\\nu}$ to get $\\breve{\\alpha} = \\frac{\\sum_i \\hat{\\nu}_i \\hat{\\zeta}_i}{\\sum_i \\hat{\\nu}_i^2}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.1\n",
    "Estimate $\\alpha$ using Post Partialling Out Lasso (PPOL)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Lasso Y using Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty_BRTyz = BRT(Z_stan, y)\n",
    "print(\"lambda_BRT =\",penalty_BRTyz.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get: lambda_BRT = 3133.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso\n",
    "fit_BRTyz = Lasso(penalty_BRTyz, max_iter=10000).fit(Z_stan,y)\n",
    "coefs=fit_BRTdz.coef_\n",
    "\n",
    "# Calculate residuals\n",
    "resyz = y-fit_BRTyz.predict(Z_stan)\n",
    "\n",
    "# Display first coefficient\n",
    "print(\"First coefficient =\",coefs[0].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get: First coefficient = -0.55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Lasso D and Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty_BRTdz = BRT(Z_stan, d)\n",
    "print(\"lambda_BRT =\",penalty_BRTdz.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        You should get: lambda_BRT = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso\n",
    "fit_BRTdz = Lasso(penalty_BRTdz, max_iter=10000).fit(Z_stan,d)\n",
    "coefs=fit_BRTdz.coef_\n",
    "\n",
    "# Calculate residuals\n",
    "resdz = d-fit_BRTdz.predict(Z_stan)\n",
    "\n",
    "# Display first coefficient\n",
    "print(\"First coefficient =\",coefs[0].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        You should get: First coefficient = -0.55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Estimate alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate alpha\n",
    "num = resdz.T@resyz\n",
    "denom = resdz.T@resdz\n",
    "alpha_PPOL = num/denom\n",
    "\n",
    "# Display alpha\n",
    "print(\"alpha_PPOL = \",alpha_PPOL.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        You should get: alpha_PPOL =  41175.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance of the PPOL estimator is given by\n",
    "\n",
    "$$\n",
    "\\breve{\\sigma}^2 = \\frac{N^{-1}\\sum_i \\hat{\\zeta}_i^2 \\hat{\\nu}_i^2}{(N^{-1}\\sum_i \\hat{\\nu}_i^2)^2}\n",
    "$$\n",
    "\n",
    "where it can be shown that \n",
    "$$\n",
    "\\sqrt{N} (\\breve{\\alpha} - \\alpha_0)/\\breve{\\sigma} \\xrightarrow{d} N(0,1)\n",
    "$$\n",
    "\n",
    "Calculate the implied variance estimate, $\\check{\\sigma}^2$, and calculate the standard deviation of $\\breve{\\alpha}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variance    \n",
    "num = resyz**2 @ resdz**2 / N\n",
    "denom = (resdz.T@resdz / N)**2\n",
    "sigma2_PPOL = num/denom\n",
    "\n",
    "# Display variance\n",
    "print(\"sigma2_PDL = \",sigma2_PPOL.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        You should get: sigma2_PDL =  15304055350.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate standard error\n",
    "se_PPOL = np.sqrt(sigma2_PPOL/N)\n",
    "\n",
    "# Display standard error\n",
    "print(\"se_PDL = \",se_PPOL.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        You should get: se_PDL =  865.44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.3\n",
    "Calculate the confidence interval for $\\breve{\\alpha}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the quantile of the standard normal distribution that corresponds to the 95% confidence interval of a two-sided test\n",
    "q = norm.ppf(1-0.025)\n",
    "\n",
    "# Calculate confidence interval\n",
    "CI_low_PPOL  = alpha_PPOL - q * se_PPOL\n",
    "CI_high_PPOL = alpha_PPOL + q * se_PPOL\n",
    "\n",
    "# Display confidence interval\n",
    "print(\"CI_PDL = \",(CI_low_PPOL.round(2),CI_high_PPOL.round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        You should get: CI_PDL =  (39478.92, 42871.38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.4\n",
    "Compare OLS, PDL and PPOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the results\n",
    "results = {'OLS'   : [alpha_OLS,    se_OLS,    CI_low_OLS,    CI_high_OLS], \n",
    "           'PSL'   : [alpha_PSL,    se_PSL,    CI_low_PSL,    CI_high_PSL],\n",
    "           'PDL'   : [alpha_PDL,    se_PDL,    CI_low_PDL,    CI_high_PDL],\n",
    "           'PPOL'  : [alpha_PPOL,   se_PPOL,   CI_low_PPOL,   CI_high_PPOL]}\n",
    "\n",
    "# Create a dataframe from the dictionary\n",
    "df_results = pd.DataFrame.from_dict(results, orient='index', columns=['Estimate of alpha', 'Standard error', 'Low bound of CI', 'High bound of CI'])\n",
    "\n",
    "# Format the dataframe to two digits after the comma\n",
    "df_results = df_results.round(2)\n",
    "\n",
    "# Display the dataframe\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    You should get:\n",
    "|      | Estimate of alpha | Standard error | Low bound of CI | High bound of CI |\n",
    "|-----:|------------------:|---------------:|----------------:|-----------------:|\n",
    "|  OLS |          37138.55 |         394.31 |        36365.72 |         37911.38 |\n",
    "|  PSL |          38147.07 |         268.92 |        37620.01 |         38674.14 |\n",
    "|  PDL |          40788.63 |         472.26 |        39863.01 |         41714.24 |\n",
    "| PPOL |          41175.15 |         865.44 |        39478.92 |         42871.38 |\n",
    "\n",
    "Why is the PDL and PPOL estimates not identical? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Part 6: Repeat with BCCH and CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Repeat Exercises using the Belloni-Chen-Chernozhukov-Hansen (BCCH) penalty level for each Lasso (which may be justified without any independence/homoscedasticity assumptions).\n",
    "* Repeat Exercises using cross-validation (CV) for each Lasso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
