{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "from scipy.stats import chi2\n",
    "from tabulate import tabulate\n",
    "\n",
    "#Suppress Future Warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Import this weeks LinearModels.py file\n",
    "import w3_LinearModels as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, x, T, year, label_y, label_x = lm.load_example_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Compare POLS to FE/FD\n",
    "### Question 1:\n",
    "\n",
    "Start by estimating eq. (3) by POLS. You should already have all the data and code that you need, print it out in a nice table. Is the unionization coefficient statistically significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled OLS\n",
      "Dependent variable: Log deflated sales\n",
      "\n",
      "               Beta      Se    t-values\n",
      "-----------  ------  ------  ----------\n",
      "Constant     0.0000  0.0050      0.0000\n",
      "Log labour   0.6748  0.0102     66.4625\n",
      "Log capital  0.3100  0.0091     33.9237\n",
      "R² = 0.914\n",
      "σ² = 0.131\n"
     ]
    }
   ],
   "source": [
    "# First, regress y on x without any transformations. Store the resulting dictionary.\n",
    "# Tip: If you want robust standard errors, you can add the argument robust_se=True to the estimate function.\n",
    "pols_result = lm.estimate(y, x, T=T)\n",
    "\n",
    "# Then, print the resulting dictionary using the provided print_table() function. The labels should have been provided to you.\n",
    "lm.print_table((label_y, label_x), pols_result, title=\"Pooled OLS\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled OLS (Robust SE)\n",
      "Dependent variable: Log deflated sales\n",
      "\n",
      "               Beta      Se    t-values\n",
      "-----------  ------  ------  ----------\n",
      "Constant     0.0000  0.0161      0.0000\n",
      "Log labour   0.6748  0.0366     18.4526\n",
      "Log capital  0.3100  0.0324      9.5810\n",
      "R² = 0.914\n",
      "σ² = 0.131\n"
     ]
    }
   ],
   "source": [
    "pols_result_robust = lm.estimate(y, x, T=T, robust_se=True)\n",
    "lm.print_table((label_y, label_x), pols_result_robust, title=\"Pooled OLS (Robust SE)\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short recap of fixed effects\n",
    "\n",
    "As discussed last time, a solution to control for fixed effects, is to \"demean\" the data. We need to calculate the mean within each person, so we define  $\\bar{y}_{i}=T^{-1}\\sum_{t=1}^{T}y_{it}, \\: \\mathbf{\\bar{x}}_{i}=T^{-1}\\sum_{t=1}^{T}\\mathbf{x}_{it}, \\: \\mathbf{\\bar{u}}_{i}=T^{-1}\\sum_{t=1}^{T}\\mathbf{u}_{it}$, and $c_i=\\bar{c}_{i} = T^{-1}\\sum_{t=1}^{T}c_{i}$.\n",
    "\n",
    "Subtracting these means from eq. (1) we are able to demean away the fixed effects,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y_{it}-\\bar{y}_{i} & =\\left(\\mathbf{x}_{it}-\\mathbf{\\bar{x}}_{i}\\right)\\mathbf{\\beta}+(\\textcolor{red}{c_{i}-c_{i}} )+\\left(u_{it}-\\bar{u}_{i}\\right) \\notag \\\\\n",
    "\\Leftrightarrow\\ddot{y}_{it} & =\\ddot{\\mathbf{x}}_{it}\\mathbf{\\beta} + \\ddot{u}_{it}. \\tag{4}\n",
    "\\end{align}\n",
    "$$\n",
    "Subtracting the mean within each person is not immediately easy. But you are provided with a `perm` function, that takes a \"transformation matrix\" Q, and uses it to permutate some vector or matrix A.\n",
    "\n",
    "In order to demean the data, we need to give this `perm` function the following transformation matrix:\n",
    "\n",
    "$$\n",
    "\\mathbf{Q}_{T}:=\\mathbf{I}_{T}-\\left(\\begin{array}{ccc}\n",
    "1/T & \\ldots & 1/T\\\\\n",
    "\\vdots & \\ddots & \\vdots\\\\\n",
    "1/T & \\ldots & 1/T\n",
    "\\end{array}\\right)_{T\\times T}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "Estimate eq. (3) by fixed effects. You need to perform the following steps:\n",
    "* Create the demeaning matrix Q.\n",
    "* Demean x and y using the `perm` function and Q.\n",
    "* Remove the columns in the demeaned x that are only zeroes and shorten the `label_x`. A function that does this is provided.\n",
    "* Estimate y on x using the demeaned arrays.\n",
    "* Print it out in a nice table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zero_columns(x, label_x, tol=1e-10):\n",
    "    \"\"\"\n",
    "    Drop columns that are (numerically) all zeros and keep their labels aligned.\n",
    "\n",
    "    Args:\n",
    "        x: regressor matrix.\n",
    "        label_x: list of column labels.\n",
    "        tol: tolerance for treating entries as zero.\n",
    "\n",
    "    Returns:\n",
    "        Filtered matrix and matching labels.\n",
    "    \"\"\"\n",
    "    mask = ~np.all(np.isclose(x, 0.0, atol=tol), axis=0)\n",
    "    x_nonzero = x[:, mask]\n",
    "    label_nonzero = [lbl for lbl, keep in zip(label_x, mask) if keep]\n",
    "    return x_nonzero, label_nonzero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Effects\n",
      "Dependent variable: Log deflated sales\n",
      "\n",
      "               Beta      Se    t-values\n",
      "-----------  ------  ------  ----------\n",
      "Log labour   0.6942  0.0417     16.6674\n",
      "Log capital  0.1546  0.0299      5.1630\n",
      "R² = 0.477\n",
      "σ² = 0.018\n"
     ]
    }
   ],
   "source": [
    "# Transform the data\n",
    "Q_T = np.eye(T) - 1/T * np.ones((T, T))\n",
    "y_dot = lm.perm(Q_T, y)\n",
    "x_dot = lm.perm(Q_T, x)\n",
    "\n",
    "# Remove the columns that are only zeroes\n",
    "x_dot, label_x_dot = remove_zero_columns(x_dot, label_x)\n",
    "\n",
    "# Estimate \n",
    "fe_result = lm.estimate(y_dot, x_dot, transform='fe', T=T, robust_se=True)\n",
    "lm.print_table((label_y, label_x_dot), fe_result, title=\"Fixed Effects\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3:\n",
    "Estimate eq. (3) by first differences. You need to perform the following steps:\n",
    "* Create the first difference matrix D.\n",
    "* First difference x and y using the `perm` function and Q.\n",
    "* Remove the columns in the first differenced x that are only zeroes and shorten the `label_x`.\n",
    "* Estimate y on x using the first differenced arrays.\n",
    "* Print it out in a nice table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Difference\n",
      "Dependent variable: Log deflated sales\n",
      "\n",
      "               Beta      Se    t-values\n",
      "-----------  ------  ------  ----------\n",
      "Log labour   0.5487  0.0292     18.8191\n",
      "Log capital  0.0630  0.0232      2.7097\n",
      "R² = 0.165\n",
      "σ² = 0.014\n"
     ]
    }
   ],
   "source": [
    "# Transform the data\n",
    "D_T = - np.eye(T-1, T) + np.eye(T-1, T, k=1)\n",
    "y_diff = lm.perm(D_T, y)\n",
    "x_diff = lm.perm(D_T, x)\n",
    "\n",
    "# Remove the columns that are only zeroes\n",
    "x_diff, label_x_diff = remove_zero_columns(x_diff, label_x)\n",
    "\n",
    "# Estimate \n",
    "fd_result = lm.estimate(y_diff, x_diff, transform='fd', T=T-1, robust_se=True)\n",
    "lm.print_table((label_y, label_x_diff), fd_result, title=\"First Difference\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: The random effects (RE) estimator.\n",
    "In part 1 we used two methods to remove unobserved heterogeneity from each person. Now, what if $E[\\text{union}_{it} c_i] = 0$? Then POLS is consistent, but not efficient, since POLS is not using the panel structure of the data. We can therefore do better with the RE estimator.\n",
    "\n",
    "## A short introduction to the RE estimator\n",
    "With the FE and FD estimators, we estimate them by OLS, but by first transforming them in a specific way. We can do the same for RE, but our mission is no longer to transform away the fixed effects, but rather to estimate the following model,\n",
    "\n",
    "$$\n",
    "\\check{y}_{it} = \\check{\\mathbf{x}}_{it}\\boldsymbol{\\beta} + \\check{v}_{it}\n",
    "$$\n",
    "\n",
    "$\\check{y}_{it} = y_{it} - \\hat{\\lambda}\\bar{y}_{it}$, $\\check{\\mathbf{x}}_{it} = \\mathbf{x}_{it} - \\hat{\\lambda}\\overline{\\mathbf{x}}_{it}$, and $\\check{v}_{it} = v_{it} - \\hat{\\lambda}\\bar{v}_{it}$, where we have gathered the errors $v_{it} = c_i + u_{it}$. We are *\"quasi-demeaning\"* the variables, by premultiplying the means by $\\hat{\\lambda}$ (see Wooldridge p. 326-328).\n",
    "\n",
    "Our challenge is thus to estimate this $\\lambda$, which we can construct in the following way:\n",
    "\n",
    "$$\n",
    "\\hat{\\lambda} = 1 - \\sqrt{\\frac{\\widehat{\\sigma}_{u}^{2}}{\\widehat{\\sigma}_{u}^{2} + T\\widehat{\\sigma}_{c}^{2}}}\n",
    "$$\n",
    "\n",
    "where $\\widehat{\\sigma}_{u}^{2}$ can be estimated from the fixed effects regression, and $\\hat{\\sigma}_{c}^{2}$ can be constructed as  $\\hat{\\sigma}_{c}^{2} = \\hat{\\sigma}_{w}^{2} - \\frac{1}{T}\\hat{\\sigma}_{u}^{2}$. Here $\\hat{\\sigma}_{w}^{2}$ is the error variance from the between estimator, \n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}_{w}^{2} = \\frac{1}{N-K}\\left(\\overline{\\mathbf{y}} - \\overline{\\mathbf{X}}\\hat{\\boldsymbol{\\beta}}_{BE}\\right)^{\\prime}\\left(\\overline{\\mathbf{y}} - \\overline{\\mathbf{X}}\\hat{\\boldsymbol{\\beta}}_{BE}\\right),\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{\\beta}_{BE}$ are the between estimater coefficients. The between-groups estimator is not something we have introduced before, but is attained by regressing the time-averaged outcomes $\\overline{y}_i$ on the time-averaged regressors $\\overline{\\mathbf{x}}_i,i=1,2,\\dotsc,N$.\n",
    "\n",
    "*Note:* There are other procedures for estimating the variances. See Wooldridge p. 294-296 for more details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: The Between Estimator\n",
    "Estimate the between groups model, which is simply the average within each individual,\n",
    "\n",
    "$$\n",
    "\\bar{y}_{i} = \\boldsymbol{\\bar{x}}_{i}\\boldsymbol{\\beta} + c_i + \\bar{u}_{i}.\n",
    "$$\n",
    "\n",
    "So instead of demeaning, like we did in FE, we just calculate the mean with the following transformation *vector* $\\mathbf{P}_T$,\n",
    "\n",
    "\\begin{equation} \n",
    "\\mathbf{P}_T \\equiv \\left( \\frac{1}{T}, \\frac{1}{T}, ..., \\frac{1}{T} \\right)_{1 \\times T}  \\notag\n",
    "\\end{equation}\n",
    "\n",
    "In order to estimate eq. (3) with the between estimator. You need to perform the following steps:\n",
    "* Create the mean vector `P`.\n",
    "* mean `x` and `y` using the `perm` function and `P`.\n",
    "* Regress `y_mean` on `x_mean`. Note that there are $N$ rows in each, not $NT$. \n",
    "* Print it out in a nice table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Between Estimator\n",
      "Dependent variable: Log deflated sales\n",
      "\n",
      "               Beta      Se    t-values\n",
      "-----------  ------  ------  ----------\n",
      "Constant     0.0000  0.0161      0.0000\n",
      "Log labour   0.6672  0.0343     19.4572\n",
      "Log capital  0.3188  0.0309     10.3230\n",
      "R² = 0.923\n",
      "σ² = 0.115\n"
     ]
    }
   ],
   "source": [
    "# Transform the data\n",
    "P_T = np.ones((1,T)) * 1/T\n",
    "y_mean = lm.perm(P_T, y)\n",
    "x_mean = lm.perm(P_T, x)\n",
    "\n",
    "# Estimate \n",
    "be_result = lm.estimate(y_mean, x_mean, transform='be', T=T)\n",
    "lm.print_table((label_y, label_x), be_result, title=\"Between Estimator\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "You should now have all the error variances that you need to calculate\n",
    "\n",
    "$$\\hat{\\lambda} = 1 - \\sqrt{\\frac{\\widehat{\\sigma}_{u}^{2}}{(\\widehat{\\sigma}_{u}^{2} + T\\widehat{\\sigma}_{c}^{2})}}. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda is approximately equal to 0.8873.\n"
     ]
    }
   ],
   "source": [
    "# Calculate lambda (note lambda is a reserved keyword in Python, so we use _lambda instead)\n",
    "sigma2_u = fe_result['sigma2']\n",
    "sigma2_w = be_result['sigma2']\n",
    "sigma2_c = sigma2_w - 1/T * sigma2_u\n",
    "_lambda = 1 - np.sqrt(sigma2_u / (sigma2_u + T*sigma2_c))\n",
    "\n",
    "# Print lambda \n",
    "print(f'Lambda is approximately equal to {_lambda.item():.4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Now we are finally ready to estimate eq. (3) with random effects. Since we have to use $\\hat{\\lambda}$ to quasi-demean within each individual, we again use the `perm` function. This time, we pass it the following transformation matrix,\n",
    "\n",
    "$$\n",
    "\\mathbf{C}_{T}:=\\mathbf{I}_{T} - \\hat{\\lambda}\\mathbf{P}_{T},\n",
    "$$\n",
    "\n",
    "where $\\mathbf{P}_{T}$ is the $1 \\times T$ transformation vector we used earlier to calculate the mean of each person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Effects\n",
      "Dependent variable: Log deflated sales\n",
      "\n",
      "               Beta      Se    t-values\n",
      "-----------  ------  ------  ----------\n",
      "Constant     0.0000  0.0168      0.0000\n",
      "Log labour   0.7197  0.0335     21.4637\n",
      "Log capital  0.1989  0.0261      7.6174\n",
      "R² = 0.642\n",
      "σ² = 0.018\n"
     ]
    }
   ],
   "source": [
    "# Transform the data\n",
    "P_T_full = np.ones((T, T)) / T\n",
    "C_T = np.eye(T) - _lambda * P_T_full\n",
    "y_re = lm.perm(C_T, y)\n",
    "x_re = lm.perm(C_T, x)\n",
    "\n",
    "# Estimate \n",
    "re_result = lm.estimate(y_re, x_re, transform='re', T=T, robust_se=True)\n",
    "lm.print_table((label_y, label_x), re_result, title=\"Random Effects\", floatfmt='.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94712a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRS Wald test (FE): 19.4029\n",
      "Critical value (5%): 3.8415\n",
      "p-value: 0.0000\n",
      "CRS Wald test (FD): 150.0280\n",
      "Critical value (5%): 3.8415\n",
      "p-value: 0.0000\n",
      "CRS Wald test (RE): 18.6793\n",
      "Critical value (5%): 3.8415\n",
      "p-value: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/t_g3d19d071dl_561zffrd9c0000gn/T/ipykernel_48460/2860914631.py:10: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  stat = float(diff.T @ la.inv(var_rb) @ diff)\n"
     ]
    }
   ],
   "source": [
    "# Constant-returns-to-scale Wald tests for FE, FD, and RE\n",
    "\n",
    "def crs_wald(result, skip=0):\n",
    "    R = np.array([[1.0, 1.0]])\n",
    "    q = np.array([[1.0]])\n",
    "    b = result['b_hat'][skip:, :]\n",
    "    cov = result['cov'][skip:, skip:]\n",
    "    diff = R @ b - q\n",
    "    var_rb = R @ cov @ R.T\n",
    "    stat = float(diff.T @ la.inv(var_rb) @ diff)\n",
    "    crit = chi2.ppf(0.95, 1)\n",
    "    pval = 1 - chi2.cdf(stat, 1)\n",
    "    return stat, crit, pval\n",
    "\n",
    "W_fe, crit_fe, p_fe = crs_wald(fe_result, skip=0)\n",
    "print(f'CRS Wald test (FE): {W_fe:.4f}')\n",
    "print(f'Critical value (5%): {crit_fe:.4f}')\n",
    "print(f'p-value: {p_fe:.4f}')\n",
    "\n",
    "W_fd, crit_fd, p_fd = crs_wald(fd_result, skip=0)\n",
    "print(f'CRS Wald test (FD): {W_fd:.4f}')\n",
    "print(f'Critical value (5%): {crit_fd:.4f}')\n",
    "print(f'p-value: {p_fd:.4f}')\n",
    "\n",
    "W_re, crit_re, p_re = crs_wald(re_result, skip=1)\n",
    "print(f'CRS Wald test (RE): {W_re:.4f}')\n",
    "print(f'Critical value (5%): {crit_re:.4f}')\n",
    "print(f'p-value: {p_re:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "659486c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strict Exogeneity Test (FE)\n",
      "Dependent variable: Log deflated sales\n",
      "\n",
      "                   Beta      Se    t-values\n",
      "---------------  ------  ------  ----------\n",
      "Log labour       0.5681  0.0397     14.3113\n",
      "Log capital      0.1495  0.0291      5.1287\n",
      "Lead log labour  0.1532  0.0281      5.4442\n",
      "R² = 0.473\n",
      "σ² = 0.016\n",
      "Wald test H0: lead coefficient = 0 -> 29.6395 (crit 5% = 3.8415, p = 0.0000)\n",
      "-> Reject H0: lead term is zero (evidence against strict exogeneity).\n"
     ]
    }
   ],
   "source": [
    "# Strict exogeneity test for FE using a lead of log labour\n",
    "F_T = np.eye(T, k=1)[:-1]\n",
    "labour_lead = lm.perm(F_T, x[:, 1].reshape(-1, 1))\n",
    "\n",
    "I_T = np.eye(T)[:-1]\n",
    "x_exo = lm.perm(I_T, x)\n",
    "y_exo = lm.perm(I_T, y)\n",
    "\n",
    "x_exo = np.hstack((x_exo, labour_lead))\n",
    "\n",
    "Q_T_exo = np.eye(T - 1) - 1/(T - 1) * np.ones((T - 1, T - 1))\n",
    "y_exo_w = lm.perm(Q_T_exo, y_exo)\n",
    "x_exo_w = lm.perm(Q_T_exo, x_exo)\n",
    "\n",
    "labels_exo = label_x + ['Lead log labour']\n",
    "x_exo_w, labels_exo = remove_zero_columns(x_exo_w, labels_exo)\n",
    "\n",
    "fe_exo_result = lm.estimate(y_exo_w, x_exo_w, transform='fe', T=T-1, robust_se=True)\n",
    "lm.print_table((label_y, labels_exo), fe_exo_result, title='Strict Exogeneity Test (FE)', floatfmt='.4f')\n",
    "\n",
    "lead_beta = fe_exo_result['b_hat'][-1, 0]\n",
    "lead_se = fe_exo_result['se'][-1, 0]\n",
    "wald_lead = (lead_beta / lead_se) ** 2\n",
    "crit_lead = chi2.ppf(0.95, 1)\n",
    "p_lead = 1 - chi2.cdf(wald_lead, 1)\n",
    "print(f'Wald test H0: lead coefficient = 0 -> {wald_lead:.4f} (crit 5% = {crit_lead:.4f}, p = {p_lead:.4f})')\n",
    "\n",
    "if p_lead < 0.05:\n",
    "    print('-> Reject H0: lead term is zero (evidence against strict exogeneity).')\n",
    "else:\n",
    "    print('-> Do NOT reject H0: no evidence against strict exogeneity in FE panel.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "217b69d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD Exogeneity Test (lead variable)\n",
      "Model: Delta log y_it = b1 Delta log K_it + b2 Delta log L_it + b3 Delta log L_{i,t+1} + Delta u_it\n",
      "\n",
      "              Variable        Beta          SE         t\n",
      "                 const     -0.0000      0.0012     -0.00\n",
      "     Delta log capital      0.0577      0.0236      2.45\n",
      "      Delta log labour      0.5304      0.0287     18.49\n",
      " Lead Delta log labour      0.1289      0.0236      5.47\n",
      "\n",
      "Test H0: Lead term = 0 -> t = 5.47, p = 0.0000 (cluster df = 440)\n",
      "-> Reject H0: lead term differs from zero (sequential exogeneity fails).\n"
     ]
    }
   ],
   "source": [
    "# Sequential exogeneity test in first differences (lead labour)\n",
    "import pandas as pd\n",
    "raw = pd.read_csv('firms.csv').sort_values(['firmid', 'year'])\n",
    "N_seq = raw['firmid'].nunique()\n",
    "T_seq = raw['year'].nunique()\n",
    "\n",
    "y_levels = np.exp(raw['ldsa'].values).reshape(-1, 1)\n",
    "x_levels = np.column_stack([\n",
    "    np.ones(raw.shape[0]),\n",
    "    np.exp(raw['lcap'].values),  # capital\n",
    "    np.exp(raw['lemp'].values),  # labour\n",
    "])\n",
    "\n",
    "lm.fd_exogeneity_lead_test(\n",
    "    y_levels,\n",
    "    x_levels,\n",
    "    N_seq,\n",
    "    T_seq,\n",
    "    cap_col=1,\n",
    "    emp_col=2,\n",
    "    logs=True,\n",
    "    drop_zeros=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4: Comparing FE and RE\n",
    "Use the results from the FE and RE estimations to compute the Hausman test statistics in eq. (7).\n",
    "\n",
    "* Start by calculating the differences in the FE and RE coefficients $\\hat{\\boldsymbol{\\beta}}_{FE} - \\hat{\\boldsymbol{\\beta}}_{RE}$ (remember to remove the time invariant variables from RE)\n",
    "* Then calculate the differences in the covariances $\\widehat{\\mathrm{avar}}(\\hat{\\boldsymbol{\\beta}}_{FE}) - \\widehat{\\mathrm{avar}}(\\hat{\\boldsymbol{\\beta}}_{RE})$ (again, remember to remove the time invariant variables for RE estimates)\n",
    "* You now have all the components to compute the Hausman test statistics in eq. (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hausman test statistic: 73.54\n",
      "Critical value (5%): 5.99\n",
      "p-value: 0.00000000\n",
      "-> Reject H0: FE and RE differ (Hausman favors FE).\n"
     ]
    }
   ],
   "source": [
    "# Hausman test using homoskedastic covariance matrices\n",
    "fe_nr = lm.estimate(y_dot, x_dot, transform='fe', T=T, robust_se=False)\n",
    "re_nr = lm.estimate(y_re, x_re, transform='re', T=T, robust_se=False)\n",
    "\n",
    "# Use only the time-varying regressors\n",
    "b_fe = fe_nr['b_hat']\n",
    "b_re = re_nr['b_hat'][1:, :]\n",
    "cov_fe = fe_nr['cov']\n",
    "cov_re = re_nr['cov'][1:, 1:]\n",
    "\n",
    "# Calculate the test statistic\n",
    "b_diff = b_fe - b_re\n",
    "cov_diff = cov_fe - cov_re\n",
    "H = b_diff.T @ la.inv(cov_diff) @ b_diff\n",
    "\n",
    "# 5% chi-square critical value with M degrees of freedom\n",
    "M = len(b_diff)\n",
    "crit_val = chi2.ppf(0.95, M)\n",
    "p_val = 1 - chi2.cdf(H.item(), M)\n",
    "\n",
    "print(f\"Hausman test statistic: {H.item():.2f}\")\n",
    "print(f\"Critical value (5%): {crit_val:.2f}\")\n",
    "print(f\"p-value: {p_val:.8f}\")\n",
    "if p_val < 0.05:\n",
    "    print('-> Reject H0: FE and RE differ (Hausman favors FE).')\n",
    "else:\n",
    "    print('-> Do NOT reject H0: no evidence against RE consistency (Hausman).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which assumption is tested by the Hausman test? What is the null hypothesis? Does the Hausman test you have conducted rely on any other assumptions (See Wooldridge, p. 328-331)? Based on your test result, which estimator would you use to estimate eq. (3)? Why?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
